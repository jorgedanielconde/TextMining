{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ivky1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.metrics import classification_report\n",
    "nltk.download('stopwords')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(row,regex,stemming=False):\n",
    "    text = re.sub(regex, ' ', row)\n",
    "    text = text.lower()\n",
    "    text = text.split()\n",
    "    if stemming:\n",
    "        snowball_stemmer = SnowballStemmer('english')\n",
    "        text = [snowball_stemmer.stem(word) for word in text if not word in stop_words]   \n",
    "    text = \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training=pd.read_csv(r\"C:\\Users\\ivky1\\University\\Year_1\\Semester_2\\Text Mining\\Project\\TextMining\\training_set.txt\", sep=\"\\t\")\n",
    "validation=pd.read_csv(r\"C:\\Users\\ivky1\\University\\Year_1\\Semester_2\\Text Mining\\Project\\TextMining\\dev_set.txt\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_processed=training.copy()\n",
    "validation_processed=validation.copy()\n",
    "training_processed.sentence=training.apply(lambda x: preprocessing(x.sentence,'[^a-zA-Z0-9!?]'),axis=1)\n",
    "validation_processed.sentence=validation.apply(lambda x: preprocessing(x.sentence,'[^a-zA-Z0-9!?]'),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_processed_baseline=training.copy()\n",
    "validation_processed_baseline=validation.copy()\n",
    "training_processed_baseline.sentence=training.apply(lambda x: preprocessing(x.sentence,'[^a-zA-Z0-9!?]',stemming=True),axis=1)\n",
    "validation_processed_baseline.sentence=validation.apply(lambda x: preprocessing(x.sentence,'[^a-zA-Z0-9!?]',stemming=True),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "cv_baseline=CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_baseline = cv_baseline.fit_transform(training_processed_baseline.sentence)\n",
    "y_train_baseline = training_processed_baseline.emotion\n",
    "X_val_baseline = cv_baseline.transform(validation_processed_baseline.sentence)\n",
    "y_val_baseline = validation_processed_baseline.emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = cv.fit_transform(training_processed.sentence)\n",
    "y_train = training_processed.emotion\n",
    "X_val = cv.transform(validation_processed.sentence)\n",
    "y_val = validation_processed.emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model,xtrain,ytrain,xval,yval):\n",
    "    model.fit(xtrain,ytrain)\n",
    "    temp_dict={\"train\":{},\"val\":{}}\n",
    "    for x,y,dataset in [(xtrain,ytrain,\"train\"),(xval,yval,\"val\")]:\n",
    "        temp_dict[dataset][\"accuracy\"]=accuracy_score(y,model.predict(x))\n",
    "        temp_dict[dataset][\"f1\"]=f1_score(y,model.predict(x), average = 'weighted')\n",
    "        temp_dict[dataset][\"precision\"]=precision_score(y,model.predict(x), average = 'weighted')\n",
    "        temp_dict[dataset][\"recall\"]=recall_score(y,model.predict(x), average = 'weighted')\n",
    "    print(classification_report(validation['emotion'], model.predict(x)))\n",
    "    return pd.DataFrame(temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pass in preprocessed data\n",
    "def evaluate_per_label(model,data,cv):\n",
    "    temp_dict={\"accuracy\":{},\"f1\":{},\"precision\":{},\"recall\":{}}\n",
    "    for i in range(1,9):\n",
    "        temp=data[data.emotion==i]\n",
    "        temp_dict[\"accuracy\"][i]=accuracy_score(temp.emotion,model.predict(cv.transform(temp.sentence)))\n",
    "        temp_dict[\"f1\"][i]=f1_score(temp.emotion,model.predict(cv.transform(temp.sentence)), average = 'weighted')\n",
    "        temp_dict[\"precision\"][i]=precision_score(temp.emotion,model.predict(cv.transform(temp.sentence)), average = 'weighted')\n",
    "        temp_dict[\"recall\"][i]=recall_score(temp.emotion,model.predict(cv.transform(temp.sentence)), average = 'weighted')  \n",
    "    return pd.DataFrame(temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb=MultinomialNB()\n",
    "svc_baseline=SVC(kernel=\"linear\")\n",
    "svc=SVC(kernel=\"linear\",C=0.5)\n",
    "sgd=SGDClassifier( loss=\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.60      0.46       211\n",
      "           2       0.40      0.48      0.44       170\n",
      "           3       0.25      0.16      0.19        77\n",
      "           4       0.43      0.28      0.34       104\n",
      "           5       0.38      0.40      0.39        97\n",
      "           6       0.36      0.23      0.28        87\n",
      "           7       0.47      0.28      0.35        96\n",
      "           8       0.39      0.30      0.34       158\n",
      "\n",
      "    accuracy                           0.38      1000\n",
      "   macro avg       0.38      0.34      0.35      1000\n",
      "weighted avg       0.38      0.38      0.37      1000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.668071</td>\n",
       "      <td>0.383000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.666308</td>\n",
       "      <td>0.370386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.686567</td>\n",
       "      <td>0.384995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.668071</td>\n",
       "      <td>0.383000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              train       val\n",
       "accuracy   0.668071  0.383000\n",
       "f1         0.666308  0.370386\n",
       "precision  0.686567  0.384995\n",
       "recall     0.668071  0.383000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(svc,X_train,y_train,X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.60      0.44       211\n",
      "           2       0.35      0.35      0.35       170\n",
      "           3       0.19      0.13      0.16        77\n",
      "           4       0.31      0.23      0.27       104\n",
      "           5       0.40      0.40      0.40        97\n",
      "           6       0.28      0.18      0.22        87\n",
      "           7       0.29      0.18      0.22        96\n",
      "           8       0.34      0.27      0.30       158\n",
      "\n",
      "    accuracy                           0.33      1000\n",
      "   macro avg       0.31      0.29      0.29      1000\n",
      "weighted avg       0.32      0.33      0.32      1000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.645214</td>\n",
       "      <td>0.333000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.643962</td>\n",
       "      <td>0.317417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.665066</td>\n",
       "      <td>0.323953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.645214</td>\n",
       "      <td>0.333000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              train       val\n",
       "accuracy   0.645214  0.333000\n",
       "f1         0.643962  0.317417\n",
       "precision  0.665066  0.323953\n",
       "recall     0.645214  0.333000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#baseline\n",
    "evaluate_model(svc_baseline,X_train_baseline,y_train_baseline,X_val_baseline,y_val_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ivky1\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ivky1\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ivky1\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ivky1\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ivky1\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ivky1\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ivky1\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ivky1\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.601896</td>\n",
       "      <td>0.751479</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.601896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.650794</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.482353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.155844</td>\n",
       "      <td>0.269663</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.155844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.278846</td>\n",
       "      <td>0.436090</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.278846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.402062</td>\n",
       "      <td>0.573529</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.402062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.229885</td>\n",
       "      <td>0.373832</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.229885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.281250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.297468</td>\n",
       "      <td>0.458537</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.297468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy        f1  precision    recall\n",
       "1  0.601896  0.751479        1.0  0.601896\n",
       "2  0.482353  0.650794        1.0  0.482353\n",
       "3  0.155844  0.269663        1.0  0.155844\n",
       "4  0.278846  0.436090        1.0  0.278846\n",
       "5  0.402062  0.573529        1.0  0.402062\n",
       "6  0.229885  0.373832        1.0  0.229885\n",
       "7  0.281250  0.439024        1.0  0.281250\n",
       "8  0.297468  0.458537        1.0  0.297468"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_per_label(svc,validation_processed,cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ivky1\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ivky1\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ivky1\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ivky1\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ivky1\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ivky1\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ivky1\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ivky1\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.597156</td>\n",
       "      <td>0.747774</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.597156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.347059</td>\n",
       "      <td>0.515284</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.347059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.129870</td>\n",
       "      <td>0.229885</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.129870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.402062</td>\n",
       "      <td>0.573529</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.402062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.183908</td>\n",
       "      <td>0.310680</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.183908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.177083</td>\n",
       "      <td>0.300885</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.177083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.265823</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.265823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy        f1  precision    recall\n",
       "1  0.597156  0.747774        1.0  0.597156\n",
       "2  0.347059  0.515284        1.0  0.347059\n",
       "3  0.129870  0.229885        1.0  0.129870\n",
       "4  0.230769  0.375000        1.0  0.230769\n",
       "5  0.402062  0.573529        1.0  0.402062\n",
       "6  0.183908  0.310680        1.0  0.183908\n",
       "7  0.177083  0.300885        1.0  0.177083\n",
       "8  0.265823  0.420000        1.0  0.265823"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_baseline.fit(X_train_baseline,y_train_baseline)\n",
    "evaluate_per_label(svc_baseline,validation_processed_baseline,cv_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.fit(X_train,y_train)\n",
    "prediction_val=svc.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation[\"prediction\"]=prediction_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What happens to the gold in our safe ?</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Natural to get cold feet .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not very lucky , is he ?</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm just a little anxious to get up there and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Did you think we don't know about your affair ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>All I ask of you is be careful .</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>You don't like jazz , pal ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Put it on .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Can you ever imagine [PERSON] being in a spot ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>You think top gun up there will be able to tel...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence  prediction\n",
       "0               What happens to the gold in our safe ?           4\n",
       "1                           Natural to get cold feet .           1\n",
       "2                             Not very lucky , is he ?           5\n",
       "3    I'm just a little anxious to get up there and ...           1\n",
       "4    Did you think we don't know about your affair ...           1\n",
       "..                                                 ...         ...\n",
       "995                   All I ask of you is be careful .           4\n",
       "996                        You don't like jazz , pal ?           1\n",
       "997                                        Put it on .           1\n",
       "998  Can you ever imagine [PERSON] being in a spot ...           5\n",
       "999  You think top gun up there will be able to tel...           4\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation[[\"sentence\",\"prediction\"]]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8c36a7226527fdc6e4bf9d59f0c9ae3f117dda07ec428f463709c7e29f2662fb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
