{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions ={1: \"Anger\",\n",
    "2: \"Anticipation\",\n",
    "3: \"Disgust\",\n",
    "4: \"Fear\",\n",
    "5: \"Joy\",\n",
    "6: \"Sadness\",\n",
    "7: \"Surprise\",\n",
    "8: \"Trust\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path):\n",
    "\n",
    "    df = pd.read_csv(path, sep = '\\t', names = ['Sentence', 'Feeling'], encoding = 'utf-8')\n",
    "    df = df.iloc[1:]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = get_data(r\"C:\\Users\\conde\\OneDrive\\OneDrive Docs\\Documents\\Masters\\2nd semester\\Text Mining\\Project\\TextMining\\training_set.txt\")\n",
    "val_data = get_data(r\"C:\\Users\\conde\\OneDrive\\OneDrive Docs\\Documents\\Masters\\2nd semester\\Text Mining\\Project\\TextMining\\dev_set.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Feeling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm too old to be traded in .</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mother said you could always tell a lady by he...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I always said I'd leave off when the time came .</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He'll be safe with me .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lay off .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13996</th>\n",
       "      <td>Yes , Commissioner .</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>The ring !</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13998</th>\n",
       "      <td>That is my greatest and most enduring love .</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13999</th>\n",
       "      <td>When I came back from the war , I had a son .</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14000</th>\n",
       "      <td>You don't have to say the words , Governor .</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Sentence Feeling\n",
       "1                          I'm too old to be traded in .       6\n",
       "2      Mother said you could always tell a lady by he...       8\n",
       "3       I always said I'd leave off when the time came .       6\n",
       "4                                He'll be safe with me .       2\n",
       "5                                              Lay off .       1\n",
       "...                                                  ...     ...\n",
       "13996                               Yes , Commissioner .       8\n",
       "13997                                         The ring !       7\n",
       "13998       That is my greatest and most enduring love .       5\n",
       "13999      When I came back from the war , I had a son .       5\n",
       "14000       You don't have to say the words , Governor .       6\n",
       "\n",
       "[14000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Feeling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What happens to the gold in our safe ?</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Natural to get cold feet .</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not very lucky , is he ?</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm just a little anxious to get up there and ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Did you think we don't know about your affair ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>All I ask of you is be careful .</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>You don't like jazz , pal ?</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Put it on .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Can you ever imagine [PERSON] being in a spot ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>You think top gun up there will be able to tel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence Feeling\n",
       "1                What happens to the gold in our safe ?       4\n",
       "2                            Natural to get cold feet .       8\n",
       "3                              Not very lucky , is he ?       7\n",
       "4     I'm just a little anxious to get up there and ...       2\n",
       "5     Did you think we don't know about your affair ...       1\n",
       "...                                                 ...     ...\n",
       "996                    All I ask of you is be careful .       4\n",
       "997                         You don't like jazz , pal ?       7\n",
       "998                                         Put it on .       1\n",
       "999   Can you ever imagine [PERSON] being in a spot ...       7\n",
       "1000  You think top gun up there will be able to tel...       1\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\conde\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\conde\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords') # removes words that are useless to prediction - connections and whatnot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\conde\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(dataframe):\n",
    "    \n",
    "    processed_corpus = []\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    for i in tqdm(range(len(dataframe))):\n",
    "        text = dataframe['Sentence'].iloc[i]\n",
    "        \n",
    "        # Remove website tags - not sure if needed in this problem. This code was copied from class\n",
    "        text = BeautifulSoup(text).get_text()\n",
    "        \n",
    "        # Remove punctuations - this is needed\n",
    "        text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "\n",
    "        # Convert to lowercase\n",
    "        text = text.lower()        \n",
    "        \n",
    "        # Convert to list from string\n",
    "        text = text.split()\n",
    "\n",
    "        # Lemmatization\n",
    "        lem = WordNetLemmatizer()\n",
    "        text = [lem.lemmatize(word) for word in text if not word in stop_words] \n",
    "        text = \" \".join(text)\n",
    "        processed_corpus.append(text)\n",
    "        \n",
    "    dataframe['Sentence'] = processed_corpus\n",
    "        \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(train_df, val_df):\n",
    "    \n",
    "    vectorizer = CountVectorizer(max_features = 5000)\n",
    "\n",
    "    vectorizer.fit(train_df['Sentence'])\n",
    "    feature_space = vectorizer.transform(val_df['Sentence'])\n",
    "    \n",
    "    return feature_space.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14000, 5000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words(train_data, train_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_grams(train_df, val_df):\n",
    "\n",
    "    vectorizer = CountVectorizer(ngram_range = (2,2))\n",
    "\n",
    "    vectorizer.fit(train_df['Sentence'])\n",
    "    feature_space = vectorizer.transform(val_df['Sentence'])\n",
    "\n",
    "    return feature_space.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(train_df, val_df):\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    vectorizer.fit(train_df['Sentence'])\n",
    "    feature_space = vectorizer.transform(val_df['Sentence'])\n",
    "\n",
    "    return feature_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_n_grams(train_df, val_df):\n",
    "    vectorizer = CountVectorizer(ngram_range = (2,2))\n",
    "    transformer = TfidfTransformer()\n",
    "\n",
    "    vectorizer.fit(train_df['Sentence'])\n",
    "    transformer.fit(vectorizer)\n",
    "    feature_space = transformer.transform(val_df['Sentence'])\n",
    "\n",
    "    return feature_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = LogisticRegression()\n",
    "# svc = SVC()\n",
    "# knn = KNeighborsClassifier()\n",
    "# nb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = [lr, svc, knn, nb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = [bag_of_words, n_grams, tf_idf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic_params = {\n",
    "#     'C': [0.1, 0.5],\n",
    "#     'penalty': ['l1', 'none'],\n",
    "#     'solver': ['lbfgs', 'saga']\n",
    "# }\n",
    "# svc_params = {\n",
    "#     'C': [0.5, 1],\n",
    "#     'kernel': ['sigmoid', 'rbf']\n",
    "# }\n",
    "# knc_params = {\n",
    "#     'n_neighbors': [5, 10],\n",
    "#     'weights' : ['uniform', 'distance']\n",
    "# }\n",
    "# nb_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params_list = [logistic_params, svc_params, knc_params, nb_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for feature in features:\n",
    "#     x = 0\n",
    "#     for model in models:\n",
    "#         gs = GridSearchCV(estimator=model,\n",
    "#                          param_grid=params_list[x],\n",
    "#                          scoring='accuracy',\n",
    "#                          verbose=1,\n",
    "#                          n_jobs=-1).fit(feature(train_data, train_data), train_data['Feeling'])\n",
    "#         x += 1\n",
    "#         y_train = gs.predict(feature(train_data, train_data))\n",
    "#         y_predict = gs.predict(feature(train_data, val_data))\n",
    "\n",
    "#         print(f\"Training Accuracy of {model} using {feature} %.3f\" \n",
    "#         %accuracy_score(train_data['Feeling'], y_train))\n",
    "\n",
    "#         print(f\"Training F1 of {model} using {feature} %.3f\" \n",
    "#         %f1_score(train_data['Feeling'], y_train, average = 'weighted'))\n",
    "\n",
    "#         print(f\"Val Accuracy of {model} using {feature} %.3f\" \n",
    "#         %accuracy_score(val_data['Feeling'], y_predict))\n",
    "\n",
    "#         print(f\"Val F1 of {model} using {feature} %.3f\" \n",
    "#         %f1_score(val_data['Feeling'], y_predict, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = 0\n",
    "# for model in models:\n",
    "#     gs = GridSearchCV(estimator=model,\n",
    "#                         param_grid=params_list[x],\n",
    "#                         scoring='accuracy',\n",
    "#                         verbose=1,\n",
    "#                         n_jobs=-1).fit(bag_of_words(train_data, train_data), train_data['Feeling'])\n",
    "#     x += 1\n",
    "#     y_train = gs.predict(bag_of_words(train_data, train_data))\n",
    "#     y_predict = gs.predict(bag_of_words(train_data, val_data))\n",
    "\n",
    "#     print(f\"Training Accuracy of {model} using bag_of_words %.3f\" \n",
    "#     %accuracy_score(train_data['Feeling'], y_train))\n",
    "\n",
    "#     print(f\"Training F1 of {model} using bag_of_words %.3f\" \n",
    "#     %f1_score(train_data['Feeling'], y_train, average = 'weighted'))\n",
    "\n",
    "#     print(f\"Val Accuracy of {model} using bag_of_words %.3f\" \n",
    "#     %accuracy_score(val_data['Feeling'], y_predict))\n",
    "\n",
    "#     print(f\"Val F1 of {model} using bag_of_words %.3f\" \n",
    "#     %f1_score(val_data['Feeling'], y_predict, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = 0\n",
    "# for model in models:\n",
    "#     gs = GridSearchCV(estimator=model,\n",
    "#                         param_grid=params_list[x],\n",
    "#                         scoring='accuracy',\n",
    "#                         verbose=1,\n",
    "#                         n_jobs=-1).fit(n_grams(train_data, train_data), train_data['Feeling'])\n",
    "#     x += 1\n",
    "#     y_train = gs.predict(n_grams(train_data, train_data))\n",
    "#     y_predict = gs.predict(n_grams(train_data, val_data))\n",
    "\n",
    "#     print(f\"Training Accuracy of {model} using n_grams %.3f\" \n",
    "#     %accuracy_score(train_data['Feeling'], y_train))\n",
    "\n",
    "#     print(f\"Training F1 of {model} using n_grams %.3f\" \n",
    "#     %f1_score(train_data['Feeling'], y_train, average = 'weighted'))\n",
    "\n",
    "#     print(f\"Val Accuracy of {model} using n_grams %.3f\" \n",
    "#     %accuracy_score(val_data['Feeling'], y_predict))\n",
    "\n",
    "#     print(f\"Val F1 of {model} using n_grams %.3f\" \n",
    "#     %f1_score(val_data['Feeling'], y_predict, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = 0\n",
    "# for model in models:\n",
    "#     gs = GridSearchCV(estimator=model,\n",
    "#                         param_grid=params_list[x],\n",
    "#                         scoring='accuracy',\n",
    "#                         verbose=1,\n",
    "#                         n_jobs=-1).fit(tf_idf(train_data, train_data), train_data['Feeling'])\n",
    "#     x += 1\n",
    "#     y_train = gs.predict(tf_idf(train_data, train_data))\n",
    "#     y_predict = gs.predict(tf_idf(train_data, val_data))\n",
    "\n",
    "#     print(f\"Training Accuracy of {model} using tf_idf %.3f\" \n",
    "#     %accuracy_score(train_data['Feeling'], y_train))\n",
    "\n",
    "#     print(f\"Training F1 of {model} using tf_idf %.3f\" \n",
    "#     %f1_score(train_data['Feeling'], y_train, average = 'weighted'))\n",
    "\n",
    "#     print(f\"Val Accuracy of {model} using tf_idf %.3f\" \n",
    "#     %accuracy_score(val_data['Feeling'], y_predict))\n",
    "\n",
    "#     print(f\"Val F1 of {model} using tf_idf %.3f\" \n",
    "#     %f1_score(val_data['Feeling'], y_predict, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelling Second Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = [lr, svc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic_params = {\n",
    "#     'C': [0.1, 0.5],\n",
    "#     'penalty': ['l1', 'none'],\n",
    "#     'solver': ['lbfgs', 'saga']\n",
    "# }\n",
    "# svc_params = {\n",
    "#     'C': [0.1, 0.5, 1, 10, 100],\n",
    "#     'kernel': ['linear', 'rbf', 'poly'],\n",
    "#     'gamma' : [0.1, 1, 10, 100]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params_list = [logistic_params, svc_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = [bag_of_words, tf_idf, n_grams, tf_idf_n_grams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Normal Bag of words\n",
    "\n",
    "# x = 0\n",
    "# for model in models:\n",
    "#     gs = GridSearchCV(estimator=model,\n",
    "#                         param_grid=params_list[x],\n",
    "#                         scoring='accuracy',\n",
    "#                         verbose=1,\n",
    "#                         n_jobs=-1).fit(bag_of_words(train_data, train_data), train_data['Feeling'])\n",
    "#     x += 1\n",
    "#     y_train = gs.predict(bag_of_words(train_data, train_data))\n",
    "#     y_predict = gs.predict(bag_of_words(train_data, val_data))\n",
    "\n",
    "#     print(f\"Training Accuracy of {model} using bag_of_words %.3f\" \n",
    "#     %accuracy_score(train_data['Feeling'], y_train))\n",
    "\n",
    "#     print(f\"Training F1 of {model} using bag_of_words %.3f\" \n",
    "#     %f1_score(train_data['Feeling'], y_train, average = 'weighted'))\n",
    "\n",
    "#     print(f\"Val Accuracy of {model} using bag_of_words %.3f\" \n",
    "#     %accuracy_score(val_data['Feeling'], y_predict))\n",
    "\n",
    "#     print(f\"Val F1 of {model} using bag_of_words %.3f\" \n",
    "#     %f1_score(val_data['Feeling'], y_predict, average = 'weighted'))\n",
    "\n",
    "#     print('Best parameters found:\\n', gs.best_params_)\n",
    "\n",
    "#     print('---------------------------------------------------------------------------------------------------------------------')\n",
    "#     # All results\n",
    "#     means = gs.cv_results_['mean_test_score']\n",
    "#     stds = gs.cv_results_['std_test_score']\n",
    "#     for mean, std, params in zip(means, stds, gs.cv_results_['params']):\n",
    "#         print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TF-IDF\n",
    "\n",
    "# x = 0\n",
    "# for model in models:\n",
    "#     gs = GridSearchCV(estimator=model,\n",
    "#                         param_grid=params_list[x],\n",
    "#                         scoring='accuracy',\n",
    "#                         verbose=1,\n",
    "#                         n_jobs=-1).fit(tf_idf(train_data, train_data), train_data['Feeling'])\n",
    "#     x += 1\n",
    "#     y_train = gs.predict(tf_idf(train_data, train_data))\n",
    "#     y_predict = gs.predict(tf_idf(train_data, val_data))\n",
    "\n",
    "#     print(f\"Training Accuracy of {model} using tf_idf %.3f\" \n",
    "#     %accuracy_score(train_data['Feeling'], y_train))\n",
    "\n",
    "#     print(f\"Training F1 of {model} using tf_idf %.3f\" \n",
    "#     %f1_score(train_data['Feeling'], y_train, average = 'weighted'))\n",
    "\n",
    "#     print(f\"Val Accuracy of {model} using tf_idf %.3f\" \n",
    "#     %accuracy_score(val_data['Feeling'], y_predict))\n",
    "\n",
    "#     print(f\"Val F1 of {model} using tf_idf %.3f\" \n",
    "#     %f1_score(val_data['Feeling'], y_predict, average = 'weighted'))\n",
    "\n",
    "#     print('Best parameters found:\\n', gs.best_params_)\n",
    "\n",
    "#     print('---------------------------------------------------------------------------------------------------------------------')\n",
    "#     # All results\n",
    "#     means = gs.cv_results_['mean_test_score']\n",
    "#     stds = gs.cv_results_['std_test_score']\n",
    "#     for mean, std, params in zip(means, stds, gs.cv_results_['params']):\n",
    "#         print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # N_Grams\n",
    "\n",
    "# x = 0\n",
    "# for model in models:\n",
    "#     gs = GridSearchCV(estimator=model,\n",
    "#                         param_grid=params_list[x],\n",
    "#                         scoring='accuracy',\n",
    "#                         verbose=1,\n",
    "#                         n_jobs=-1).fit(n_grams(train_data, train_data), train_data['Feeling'])\n",
    "#     x += 1\n",
    "#     y_train = gs.predict(n_grams(train_data, train_data))\n",
    "#     y_predict = gs.predict(n_grams(train_data, val_data))\n",
    "\n",
    "#     print(f\"Training Accuracy of {model} using n_grams %.3f\" \n",
    "#     %accuracy_score(train_data['Feeling'], y_train))\n",
    "\n",
    "#     print(f\"Training F1 of {model} using n_grams %.3f\" \n",
    "#     %f1_score(train_data['Feeling'], y_train, average = 'weighted'))\n",
    "\n",
    "#     print(f\"Val Accuracy of {model} using n_grams %.3f\" \n",
    "#     %accuracy_score(val_data['Feeling'], y_predict))\n",
    "\n",
    "#     print(f\"Val F1 of {model} using n_grams %.3f\" \n",
    "#     %f1_score(val_data['Feeling'], y_predict, average = 'weighted'))\n",
    "\n",
    "#     print('Best parameters found:\\n', gs.best_params_)\n",
    "\n",
    "#     print('---------------------------------------------------------------------------------------------------------------------')\n",
    "#     # All results\n",
    "#     means = gs.cv_results_['mean_test_score']\n",
    "#     stds = gs.cv_results_['std_test_score']\n",
    "#     for mean, std, params in zip(means, stds, gs.cv_results_['params']):\n",
    "#         print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TF_IDF_N_Grams\n",
    "\n",
    "# x = 0\n",
    "# for model in models:\n",
    "#     gs = GridSearchCV(estimator=model,\n",
    "#                         param_grid=params_list[x],\n",
    "#                         scoring='accuracy',\n",
    "#                         verbose=1,\n",
    "#                         n_jobs=-1).fit(tf_idf_n_grams(train_data, train_data), train_data['Feeling'])\n",
    "#     x += 1\n",
    "#     y_train = gs.predict(tf_idf_n_grams(train_data, train_data))\n",
    "#     y_predict = gs.predict(tf_idf_n_grams(train_data, val_data))\n",
    "\n",
    "#     print(f\"Training Accuracy of {model} using tf_idf_n_grams %.3f\" \n",
    "#     %accuracy_score(train_data['Feeling'], y_train))\n",
    "\n",
    "#     print(f\"Training F1 of {model} using tf_idf_n_grams %.3f\" \n",
    "#     %f1_score(train_data['Feeling'], y_train, average = 'weighted'))\n",
    "\n",
    "#     print(f\"Val Accuracy of {model} using tf_idf_n_grams %.3f\" \n",
    "#     %accuracy_score(val_data['Feeling'], y_predict))\n",
    "\n",
    "#     print(f\"Val F1 of {model} using tf_idf_n_grams %.3f\" \n",
    "#     %f1_score(val_data['Feeling'], y_predict, average = 'weighted'))\n",
    "\n",
    "#     print('Best parameters found:\\n', gs.best_params_)\n",
    "\n",
    "#     print('---------------------------------------------------------------------------------------------------------------------')\n",
    "#     # All results\n",
    "#     means = gs.cv_results_['mean_test_score']\n",
    "#     stds = gs.cv_results_['std_test_score']\n",
    "#     for mean, std, params in zip(means, stds, gs.cv_results_['params']):\n",
    "#         print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LR + BoW\n",
    "\n",
    "# data = bag_of_words(train_data, train_data)\n",
    "# eval_data = bag_of_words(train_data, val_data)\n",
    "\n",
    "# method = \"bag of words\"\n",
    "# model_used = 'Linear Regression'\n",
    "\n",
    "# lr_bag_gs = GridSearchCV(estimator=lr,\n",
    "#                     param_grid=params_list[0],\n",
    "#                     scoring='accuracy',\n",
    "#                     verbose=1,\n",
    "#                     n_jobs=-1).fit(data, train_data['Feeling'])\n",
    "# y_train = lr_bag_gs.predict(data)\n",
    "# y_predict = lr_bag_gs.predict(eval_data)\n",
    "\n",
    "# print(f\"Training Accuracy of {model_used} using {method} %.3f\" \n",
    "# %accuracy_score(train_data['Feeling'], y_train))\n",
    "\n",
    "# print(f\"Training F1 of {model_used} using {method} %.3f\" \n",
    "# %f1_score(train_data['Feeling'], y_train, average = 'weighted'))\n",
    "\n",
    "# print(f\"Val Accuracy of {model_used} using {method} %.3f\" \n",
    "# %accuracy_score(val_data['Feeling'], y_predict))\n",
    "\n",
    "# print(f\"Val F1 of {model_used} using {method} %.3f\" \n",
    "# %f1_score(val_data['Feeling'], y_predict, average = 'weighted'))\n",
    "\n",
    "# print('Best parameters found:\\n', lr_bag_gs.best_params_)\n",
    "\n",
    "# print('---------------------------------------------------------------------------------------------------------------------')\n",
    "# # All results\n",
    "# means = lr_bag_gs.cv_results_['mean_test_score']\n",
    "# stds = lr_bag_gs.cv_results_['std_test_score']\n",
    "# for mean, std, params in zip(means, stds, lr_bag_gs.cv_results_['params']):\n",
    "#     print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #LR + TF-IDF\n",
    "\n",
    "# data = tf_idf(train_data, train_data)\n",
    "# eval_data = tf_idf(train_data, val_data)\n",
    "\n",
    "# method = \"tf-idf\"\n",
    "# model_used = 'Linear Regression'\n",
    "\n",
    "# lr_tfidf_gs = GridSearchCV(estimator=lr,\n",
    "#                     param_grid=params_list[0],\n",
    "#                     scoring='accuracy',\n",
    "#                     verbose=1,\n",
    "#                     n_jobs=-1).fit(data, train_data['Feeling'])\n",
    "# y_train = lr_tfidf_gs.predict(data)\n",
    "# y_predict = lr_tfidf_gs.predict(eval_data)\n",
    "\n",
    "# print(f\"Training Accuracy of {model_used} using {method} %.3f\" \n",
    "# %accuracy_score(train_data['Feeling'], y_train))\n",
    "\n",
    "# print(f\"Training F1 of {model_used} using {method} %.3f\" \n",
    "# %f1_score(train_data['Feeling'], y_train, average = 'weighted'))\n",
    "\n",
    "# print(f\"Val Accuracy of {model_used} using {method} %.3f\" \n",
    "# %accuracy_score(val_data['Feeling'], y_predict))\n",
    "\n",
    "# print(f\"Val F1 of {model_used} using {method} %.3f\" \n",
    "# %f1_score(val_data['Feeling'], y_predict, average = 'weighted'))\n",
    "\n",
    "# print('Best parameters found:\\n', lr_tfidf_gs.best_params_)\n",
    "\n",
    "# print('---------------------------------------------------------------------------------------------------------------------')\n",
    "# # All results\n",
    "# means = lr_tfidf_gs.cv_results_['mean_test_score']\n",
    "# stds = lr_tfidf_gs.cv_results_['std_test_score']\n",
    "# for mean, std, params in zip(means, stds, lr_tfidf_gs.cv_results_['params']):\n",
    "#     print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LR + N-Grams\n",
    "\n",
    "# data = n_grams(train_data, train_data)\n",
    "# eval_data = n_grams(train_data, val_data)\n",
    "\n",
    "# method = \"n-grams\"\n",
    "# model_used = 'Linear Regression'\n",
    "\n",
    "# lr_ngrams_gs = GridSearchCV(estimator=lr,\n",
    "#                     param_grid=params_list[0],\n",
    "#                     scoring='accuracy',\n",
    "#                     verbose=1,\n",
    "#                     n_jobs=-1).fit(data, train_data['Feeling'])\n",
    "# y_train = lr_ngrams_gs.predict(data)\n",
    "# y_predict = lr_ngrams_gs.predict(eval_data)\n",
    "\n",
    "# print(f\"Training Accuracy of {model_used} using {method} %.3f\" \n",
    "# %accuracy_score(train_data['Feeling'], y_train))\n",
    "\n",
    "# print(f\"Training F1 of {model_used} using {method} %.3f\" \n",
    "# %f1_score(train_data['Feeling'], y_train, average = 'weighted'))\n",
    "\n",
    "# print(f\"Val Accuracy of {model_used} using {method} %.3f\" \n",
    "# %accuracy_score(val_data['Feeling'], y_predict))\n",
    "\n",
    "# print(f\"Val F1 of {model_used} using {method} %.3f\" \n",
    "# %f1_score(val_data['Feeling'], y_predict, average = 'weighted'))\n",
    "\n",
    "# print('Best parameters found:\\n', lr_ngrams_gs.best_params_)\n",
    "\n",
    "# print('---------------------------------------------------------------------------------------------------------------------')\n",
    "# # All results\n",
    "# means = lr_ngrams_gs.cv_results_['mean_test_score']\n",
    "# stds = lr_ngrams_gs.cv_results_['std_test_score']\n",
    "# for mean, std, params in zip(means, stds, lr_ngrams_gs.cv_results_['params']):\n",
    "#     print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #LR + TD-IDF of N-Grams\n",
    "\n",
    "# data = tf_idf_n_grams(train_data, train_data)\n",
    "# eval_data = tf_idf_n_grams(train_data, val_data)\n",
    "\n",
    "# method = \"tf-idf of n-grams\"\n",
    "# model_used = 'Linear Regression'\n",
    "\n",
    "# lr_ntfidf_gs = GridSearchCV(estimator=lr,\n",
    "#                     param_grid=params_list[0],\n",
    "#                     scoring='accuracy',\n",
    "#                     verbose=1,\n",
    "#                     n_jobs=-1).fit(data, train_data['Feeling'])\n",
    "# y_train = lr_ntfidf_gs.predict(data)\n",
    "# y_predict = lr_ntfidf_gs.predict(eval_data)\n",
    "\n",
    "# print(f\"Training Accuracy of {model_used} using {method} %.3f\" \n",
    "# %accuracy_score(train_data['Feeling'], y_train))\n",
    "\n",
    "# print(f\"Training F1 of {model_used} using {method} %.3f\" \n",
    "# %f1_score(train_data['Feeling'], y_train, average = 'weighted'))\n",
    "\n",
    "# print(f\"Val Accuracy of {model_used} using {method} %.3f\" \n",
    "# %accuracy_score(val_data['Feeling'], y_predict))\n",
    "\n",
    "# print(f\"Val F1 of {model_used} using {method} %.3f\" \n",
    "# %f1_score(val_data['Feeling'], y_predict, average = 'weighted'))\n",
    "\n",
    "# print('Best parameters found:\\n', lr_ntfidf_gs.best_params_)\n",
    "\n",
    "# print('---------------------------------------------------------------------------------------------------------------------')\n",
    "# # All results\n",
    "# means = lr_ntfidf_gs.cv_results_['mean_test_score']\n",
    "# stds = lr_ntfidf_gs.cv_results_['std_test_score']\n",
    "# for mean, std, params in zip(means, stds, lr_ntfidf_gs.cv_results_['params']):\n",
    "#     print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SVC + BoW\n",
    "\n",
    "# data = bag_of_words(train_data, train_data)\n",
    "# eval_data = bag_of_words(train_data, val_data)\n",
    "\n",
    "# method = \"bag of words\"\n",
    "# model_used = 'SVC'\n",
    "\n",
    "# lr_bag_gs = GridSearchCV(estimator=svc,\n",
    "#                     param_grid=params_list[1],\n",
    "#                     scoring='accuracy',\n",
    "#                     verbose=1,\n",
    "#                     n_jobs=-1).fit(data, train_data['Feeling'])\n",
    "# y_train = lr_bag_gs.predict(data)\n",
    "# y_predict = lr_bag_gs.predict(eval_data)\n",
    "\n",
    "# print(f\"Training Accuracy of {model_used} using {method} %.3f\" \n",
    "# %accuracy_score(train_data['Feeling'], y_train))\n",
    "\n",
    "# print(f\"Training F1 of {model_used} using {method} %.3f\" \n",
    "# %f1_score(train_data['Feeling'], y_train, average = 'weighted'))\n",
    "\n",
    "# print(f\"Val Accuracy of {model_used} using {method} %.3f\" \n",
    "# %accuracy_score(val_data['Feeling'], y_predict))\n",
    "\n",
    "# print(f\"Val F1 of {model_used} using {method} %.3f\" \n",
    "# %f1_score(val_data['Feeling'], y_predict, average = 'weighted'))\n",
    "\n",
    "# print('Best parameters found:\\n', lr_bag_gs.best_params_)\n",
    "\n",
    "# print('---------------------------------------------------------------------------------------------------------------------')\n",
    "# # All results\n",
    "# means = lr_bag_gs.cv_results_['mean_test_score']\n",
    "# stds = lr_bag_gs.cv_results_['std_test_score']\n",
    "# for mean, std, params in zip(means, stds, lr_bag_gs.cv_results_['params']):\n",
    "#     print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SVC + BoW\n",
    "\n",
    "# data = tf_idf(train_data, train_data)\n",
    "# eval_data = tf_idf(train_data, val_data)\n",
    "\n",
    "# method = \"bag of words\"\n",
    "# model_used = 'SVC'\n",
    "\n",
    "# svc_tfidf_gs = GridSearchCV(estimator=svc,\n",
    "#                     param_grid=params_list[1],\n",
    "#                     scoring='accuracy',\n",
    "#                     verbose=1,\n",
    "#                     n_jobs=-1).fit(data, train_data['Feeling'])\n",
    "# y_train = svc_tfidf_gs.predict(data)\n",
    "# y_predict = svc_tfidf_gs.predict(eval_data)\n",
    "\n",
    "# print(f\"Training Accuracy of {model_used} using {method} %.3f\" \n",
    "# %accuracy_score(train_data['Feeling'], y_train))\n",
    "\n",
    "# print(f\"Training F1 of {model_used} using {method} %.3f\" \n",
    "# %f1_score(train_data['Feeling'], y_train, average = 'weighted'))\n",
    "\n",
    "# print(f\"Val Accuracy of {model_used} using {method} %.3f\" \n",
    "# %accuracy_score(val_data['Feeling'], y_predict))\n",
    "\n",
    "# print(f\"Val F1 of {model_used} using {method} %.3f\" \n",
    "# %f1_score(val_data['Feeling'], y_predict, average = 'weighted'))\n",
    "\n",
    "# print('Best parameters found:\\n', svc_tfidf_gs.best_params_)\n",
    "\n",
    "# print('---------------------------------------------------------------------------------------------------------------------')\n",
    "# # All results\n",
    "# means = svc_tfidf_gs.cv_results_['mean_test_score']\n",
    "# stds = svc_tfidf_gs.cv_results_['std_test_score']\n",
    "# for mean, std, params in zip(means, stds, svc_tfidf_gs.cv_results_['params']):\n",
    "#     print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDClassifier(loss = 'log', random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy of SGDCassifier using bag of words 0.596\n",
      "Training F1 of SGDCassifier using bag of words 0.594\n",
      "Val Accuracy of SGDCassifier using bag of words 0.380\n",
      "Val F1 of SGDCassifier using bag of words 0.372\n"
     ]
    }
   ],
   "source": [
    "# SGDCassifier + BoW\n",
    "\n",
    "data = bag_of_words(train_data, train_data)\n",
    "eval_data = bag_of_words(train_data, val_data)\n",
    "\n",
    "method = \"bag of words\"\n",
    "model_used = 'SGDCassifier'\n",
    "\n",
    "fitted = sgd.fit(data, train_data['Feeling'])\n",
    "y_train = fitted.predict(data)\n",
    "y_predict = fitted.predict(eval_data)\n",
    "\n",
    "print(f\"Training Accuracy of {model_used} using {method} %.3f\" \n",
    "%accuracy_score(train_data['Feeling'], y_train))\n",
    "\n",
    "print(f\"Training F1 of {model_used} using {method} %.3f\" \n",
    "%f1_score(train_data['Feeling'], y_train, average = 'weighted'))\n",
    "\n",
    "print(f\"Val Accuracy of {model_used} using {method} %.3f\" \n",
    "%accuracy_score(val_data['Feeling'], y_predict))\n",
    "\n",
    "print(f\"Val F1 of {model_used} using {method} %.3f\" \n",
    "%f1_score(val_data['Feeling'], y_predict, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests on solution set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions = pd.read_csv(r\"C:\\Users\\conde\\OneDrive\\OneDrive Docs\\Documents\\Masters\\2nd semester\\Text Mining\\Project\\TextMining\\test_solution.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = get_data(r\"C:\\Users\\conde\\OneDrive\\OneDrive Docs\\Documents\\Masters\\2nd semester\\Text Mining\\Project\\TextMining\\test_set.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Feeling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Come , let's go get that automobile .</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Well , some other time , then ?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He's in trouble . Boy ?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Criminal gang unit to take control .</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>By Molto . No discussion . Interview .</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>Let's do some good .</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Hey , you're looking good .</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>Have they moved the embassy , or are you hijac...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>What that !</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>Imagine interplanetary trade , how exciting th...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence  Feeling\n",
       "1                 Come , let's go get that automobile .      NaN\n",
       "2                       Well , some other time , then ?      NaN\n",
       "3                               He's in trouble . Boy ?      NaN\n",
       "4                  Criminal gang unit to take control .      NaN\n",
       "5                By Molto . No discussion . Interview .      NaN\n",
       "...                                                 ...      ...\n",
       "1996                               Let's do some good .      NaN\n",
       "1997                        Hey , you're looking good .      NaN\n",
       "1998  Have they moved the embassy , or are you hijac...      NaN\n",
       "1999                                        What that !      NaN\n",
       "2000  Imagine interplanetary trade , how exciting th...      NaN\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['Feeling'] = fitted.predict(bag_of_words(train_data, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Feeling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Come , let's go get that automobile .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Well , some other time , then ?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He's in trouble . Boy ?</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Criminal gang unit to take control .</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>By Molto . No discussion . Interview .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>Let's do some good .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Hey , you're looking good .</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>Have they moved the embassy , or are you hijac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>What that !</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>Imagine interplanetary trade , how exciting th...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence Feeling\n",
       "1                 Come , let's go get that automobile .       2\n",
       "2                       Well , some other time , then ?       2\n",
       "3                               He's in trouble . Boy ?       4\n",
       "4                  Criminal gang unit to take control .       8\n",
       "5                By Molto . No discussion . Interview .       1\n",
       "...                                                 ...     ...\n",
       "1996                               Let's do some good .       2\n",
       "1997                        Hey , you're looking good .       5\n",
       "1998  Have they moved the embassy , or are you hijac...       1\n",
       "1999                                        What that !       7\n",
       "2000  Imagine interplanetary trade , how exciting th...       2\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f75349f0115edef59d2563a5bc200fd0b17f0436f327d8366fe82b1301064ec4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('textmining')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
