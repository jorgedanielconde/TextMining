{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer, CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path):\n",
    "\n",
    "    df = pd.read_csv(path, sep = '\\t', names = ['Sentence', 'Feeling'], encoding = 'utf-8')\n",
    "    df = df.iloc[1:]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = get_data(r\"C:\\Users\\ivky1\\University\\Year_1\\Semester_2\\Text Mining\\Project\\TextMining\\training_set.txt\")\n",
    "val_data = get_data(r\"C:\\Users\\ivky1\\University\\Year_1\\Semester_2\\Text Mining\\Project\\TextMining\\dev_set.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ivky1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ivky1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\ivky1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords') \n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(dataframe):\n",
    "    \n",
    "    processed_corpus = []\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    for i in tqdm(range(len(dataframe))):\n",
    "        text = dataframe['Sentence'].iloc[i]\n",
    "        \n",
    "        # Remove punctuations - this is needed\n",
    "        text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "\n",
    "        # Convert to lowercase\n",
    "        text = text.lower()        \n",
    "        \n",
    "        # Convert to list from string\n",
    "        text = text.split()\n",
    "\n",
    "        # Lemmatization\n",
    "        lem = WordNetLemmatizer()\n",
    "        text = [lem.lemmatize(word) for word in text if not word in stop_words] \n",
    "        text = \" \".join(text)\n",
    "        processed_corpus.append(text)\n",
    "        \n",
    "    dataframe['Sentence'] = processed_corpus\n",
    "        \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teacher_bog(train_df, val_df):\n",
    "    vectorizer = CountVectorizer()\n",
    "    vectorizer.fit(train_df['Sentence'])\n",
    "    feature_space = vectorizer.transform(val_df['Sentence'])\n",
    "\n",
    "    return feature_space.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(train_df, val_df):\n",
    "    \n",
    "    vectorizer = CountVectorizer(max_features = 5000)\n",
    "    vectorizer.fit(train_df['Sentence'])\n",
    "    feature_space = vectorizer.transform(val_df['Sentence'])\n",
    "    \n",
    "    return feature_space.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14000, 5000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words(train_data, train_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_grams(train_df, val_df):\n",
    "\n",
    "    vectorizer = CountVectorizer(ngram_range = (2,2))\n",
    "    vectorizer.fit(train_df['Sentence'])\n",
    "    feature_space = vectorizer.transform(val_df['Sentence'])\n",
    "\n",
    "    return feature_space.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(train_df, val_df):\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectorizer.fit(train_df['Sentence'])\n",
    "    feature_space = vectorizer.transform(val_df['Sentence'])\n",
    "\n",
    "    return feature_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_n_grams(train_df, val_df):\n",
    "    vectorizer = CountVectorizer(ngram_range = (2,2))\n",
    "    transformer = TfidfTransformer()\n",
    "\n",
    "    vectorizer.fit(train_df['Sentence'])\n",
    "    transformer.fit(vectorizer)\n",
    "    feature_space = transformer.transform(val_df['Sentence'])\n",
    "\n",
    "    return feature_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDClassifier(loss = 'log', random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy of SGDCassifier using bag of words 0.596\n",
      "Training F1 of SGDCassifier using bag of words 0.594\n",
      "Val Accuracy of SGDCassifier using bag of words 0.380\n",
      "Val F1 of SGDCassifier using bag of words 0.372\n"
     ]
    }
   ],
   "source": [
    "# Best model: SGDClassifier + BoW\n",
    "\n",
    "data = bag_of_words(train_data, train_data)\n",
    "eval_data = bag_of_words(train_data, val_data)\n",
    "\n",
    "method = \"bag of words\"\n",
    "model_used = 'SGDCassifier'\n",
    "\n",
    "fitted = sgd.fit(data, train_data['Feeling'])\n",
    "y_train = fitted.predict(data)\n",
    "y_predict = fitted.predict(eval_data)\n",
    "\n",
    "print(f\"Training Accuracy of {model_used} using {method} %.3f\" \n",
    "%accuracy_score(train_data['Feeling'], y_train))\n",
    "\n",
    "print(f\"Training F1 of {model_used} using {method} %.3f\" \n",
    "%f1_score(train_data['Feeling'], y_train, average = 'weighted'))\n",
    "\n",
    "print(f\"Val Accuracy of {model_used} using {method} %.3f\" \n",
    "%accuracy_score(val_data['Feeling'], y_predict))\n",
    "\n",
    "print(f\"Val F1 of {model_used} using {method} %.3f\" \n",
    "%f1_score(val_data['Feeling'], y_predict, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivky1\\AppData\\Local\\Temp\\ipykernel_63328\\2719440103.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm(range(len(dataframe))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fbaf3c4dd7a478e82a420fca0f74734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Feeling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>happens gold safe</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>natural get cold foot</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lucky</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>little anxious get whoop et as</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>think know affair government official</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>ask careful</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>like jazz pal</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>put</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>ever imagine person spot like</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>think top gun able tell somebody following u</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Sentence Feeling\n",
       "1                                happens gold safe       4\n",
       "2                            natural get cold foot       8\n",
       "3                                            lucky       7\n",
       "4                   little anxious get whoop et as       2\n",
       "5            think know affair government official       1\n",
       "...                                            ...     ...\n",
       "996                                    ask careful       4\n",
       "997                                  like jazz pal       7\n",
       "998                                            put       1\n",
       "999                  ever imagine person spot like       7\n",
       "1000  think top gun able tell somebody following u       1\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_val = val_data.copy()\n",
    "process(processed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "strong_baseline = SVC(kernel = 'linear').fit(teacher_bog(train_data, train_data), train_data['Feeling'])\n",
    "teacher_pred = strong_baseline.predict(teacher_bog(train_data, processed_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_model = [accuracy_score(val_data['Feeling'], y_predict), f1_score(val_data['Feeling'], y_predict, average = 'weighted'), recall_score(val_data['Feeling'], y_predict, average = 'weighted'), precision_score(val_data['Feeling'], y_predict, average = 'weighted')]\n",
    "teacher_model = [accuracy_score(val_data['Feeling'], teacher_pred), f1_score(val_data['Feeling'], teacher_pred, average = 'weighted'), recall_score(val_data['Feeling'], teacher_pred, average = 'weighted'), precision_score(val_data['Feeling'], teacher_pred, average = 'weighted')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>our model</th>\n",
       "      <td>0.380</td>\n",
       "      <td>0.372251</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.377286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strong baseline</th>\n",
       "      <td>0.346</td>\n",
       "      <td>0.330264</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.346213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   acc        f1  recall  precision\n",
       "our model        0.380  0.372251   0.380   0.377286\n",
       "strong baseline  0.346  0.330264   0.346   0.346213"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([our_model, teacher_model], columns = ['acc', 'f1', 'recall', 'precision'], index = ['our model', 'strong baseline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.4000    0.5403    0.4597       211\n",
      "           2     0.3713    0.4412    0.4032       170\n",
      "           3     0.2979    0.1818    0.2258        77\n",
      "           4     0.4000    0.3077    0.3478       104\n",
      "           5     0.4021    0.4021    0.4021        97\n",
      "           6     0.4167    0.2874    0.3401        87\n",
      "           7     0.3582    0.2500    0.2945        96\n",
      "           8     0.3519    0.3608    0.3563       158\n",
      "\n",
      "    accuracy                         0.3800      1000\n",
      "   macro avg     0.3747    0.3464    0.3537      1000\n",
      "weighted avg     0.3773    0.3800    0.3723      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(val_data['Feeling'], y_predict, target_names=np.unique(val_data['Feeling']), digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests on solution set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = get_data(r\"C:\\Users\\ivky1\\University\\Year_1\\Semester_2\\Text Mining\\Project\\TextMining\\test_set.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Feeling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Come , let's go get that automobile .</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Well , some other time , then ?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He's in trouble . Boy ?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Criminal gang unit to take control .</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>By Molto . No discussion . Interview .</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>Let's do some good .</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Hey , you're looking good .</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>Have they moved the embassy , or are you hijac...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>What that !</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>Imagine interplanetary trade , how exciting th...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence  Feeling\n",
       "1                 Come , let's go get that automobile .      NaN\n",
       "2                       Well , some other time , then ?      NaN\n",
       "3                               He's in trouble . Boy ?      NaN\n",
       "4                  Criminal gang unit to take control .      NaN\n",
       "5                By Molto . No discussion . Interview .      NaN\n",
       "...                                                 ...      ...\n",
       "1996                               Let's do some good .      NaN\n",
       "1997                        Hey , you're looking good .      NaN\n",
       "1998  Have they moved the embassy , or are you hijac...      NaN\n",
       "1999                                        What that !      NaN\n",
       "2000  Imagine interplanetary trade , how exciting th...      NaN\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['Feeling'] = fitted.predict(bag_of_words(train_data, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Feeling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Come , let's go get that automobile .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Well , some other time , then ?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He's in trouble . Boy ?</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Criminal gang unit to take control .</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>By Molto . No discussion . Interview .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>Let's do some good .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Hey , you're looking good .</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>Have they moved the embassy , or are you hijac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>What that !</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>Imagine interplanetary trade , how exciting th...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence Feeling\n",
       "1                 Come , let's go get that automobile .       2\n",
       "2                       Well , some other time , then ?       2\n",
       "3                               He's in trouble . Boy ?       4\n",
       "4                  Criminal gang unit to take control .       8\n",
       "5                By Molto . No discussion . Interview .       1\n",
       "...                                                 ...     ...\n",
       "1996                               Let's do some good .       2\n",
       "1997                        Hey , you're looking good .       5\n",
       "1998  Have they moved the embassy , or are you hijac...       1\n",
       "1999                                        What that !       7\n",
       "2000  Imagine interplanetary trade , how exciting th...       2\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions ={1: \"Anger\",\n",
    "2: \"Anticipation\",\n",
    "3: \"Disgust\",\n",
    "4: \"Fear\",\n",
    "5: \"Joy\",\n",
    "6: \"Sadness\",\n",
    "7: \"Surprise\",\n",
    "8: \"Trust\"}"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8c36a7226527fdc6e4bf9d59f0c9ae3f117dda07ec428f463709c7e29f2662fb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
