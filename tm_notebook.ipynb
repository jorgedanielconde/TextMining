{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions ={1: \"Anger\",\n",
    "2: \"Anticipation\",\n",
    "3: \"Disgust\",\n",
    "4: \"Fear\",\n",
    "5: \"Joy\",\n",
    "6: \"Sadness\",\n",
    "7: \"Surprise\",\n",
    "8: \"Trust\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path):\n",
    "\n",
    "    df = pd.read_csv(path, sep = '\\t', names = ['Sentence', 'Feeling'], encoding = 'utf-8')\n",
    "    df = df.iloc[1:]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = get_data(r\"C:\\Users\\conde\\OneDrive\\OneDrive Docs\\Documents\\Masters\\2nd semester\\Text Mining\\Project\\TextMining\\training_set.txt\")\n",
    "val_data = get_data(r\"C:\\Users\\conde\\OneDrive\\OneDrive Docs\\Documents\\Masters\\2nd semester\\Text Mining\\Project\\TextMining\\dev_set.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Feeling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm too old to be traded in .</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mother said you could always tell a lady by he...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I always said I'd leave off when the time came .</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He'll be safe with me .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lay off .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13996</th>\n",
       "      <td>Yes , Commissioner .</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>The ring !</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13998</th>\n",
       "      <td>That is my greatest and most enduring love .</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13999</th>\n",
       "      <td>When I came back from the war , I had a son .</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14000</th>\n",
       "      <td>You don't have to say the words , Governor .</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Sentence Feeling\n",
       "1                          I'm too old to be traded in .       6\n",
       "2      Mother said you could always tell a lady by he...       8\n",
       "3       I always said I'd leave off when the time came .       6\n",
       "4                                He'll be safe with me .       2\n",
       "5                                              Lay off .       1\n",
       "...                                                  ...     ...\n",
       "13996                               Yes , Commissioner .       8\n",
       "13997                                         The ring !       7\n",
       "13998       That is my greatest and most enduring love .       5\n",
       "13999      When I came back from the war , I had a son .       5\n",
       "14000       You don't have to say the words , Governor .       6\n",
       "\n",
       "[14000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Feeling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What happens to the gold in our safe ?</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Natural to get cold feet .</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not very lucky , is he ?</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm just a little anxious to get up there and ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Did you think we don't know about your affair ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>All I ask of you is be careful .</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>You don't like jazz , pal ?</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Put it on .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Can you ever imagine [PERSON] being in a spot ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>You think top gun up there will be able to tel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence Feeling\n",
       "1                What happens to the gold in our safe ?       4\n",
       "2                            Natural to get cold feet .       8\n",
       "3                              Not very lucky , is he ?       7\n",
       "4     I'm just a little anxious to get up there and ...       2\n",
       "5     Did you think we don't know about your affair ...       1\n",
       "...                                                 ...     ...\n",
       "996                    All I ask of you is be careful .       4\n",
       "997                         You don't like jazz , pal ?       7\n",
       "998                                         Put it on .       1\n",
       "999   Can you ever imagine [PERSON] being in a spot ...       7\n",
       "1000  You think top gun up there will be able to tel...       1\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\conde\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\conde\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords') # removes words that are useless to prediction - connections and whatnot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\conde\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(dataframe):\n",
    "    \n",
    "    processed_corpus = []\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    for i in tqdm(range(len(dataframe))):\n",
    "        text = dataframe['Sentence'].iloc[i]\n",
    "        \n",
    "        # Remove website tags - not sure if needed in this problem. This code was copied from class\n",
    "        text = BeautifulSoup(text).get_text()\n",
    "        \n",
    "        # Remove punctuations - this is needed\n",
    "        text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "\n",
    "        # Convert to lowercase\n",
    "        text = text.lower()        \n",
    "        \n",
    "        # Convert to list from string\n",
    "        text = text.split()\n",
    "\n",
    "        # Lemmatization\n",
    "        lem = WordNetLemmatizer()\n",
    "        text = [lem.lemmatize(word) for word in text if not word in stop_words] \n",
    "        text = \" \".join(text)\n",
    "        processed_corpus.append(text)\n",
    "        \n",
    "    dataframe['Sentence'] = processed_corpus\n",
    "        \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(train_df, val_df):\n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "\n",
    "    vectorizer.fit(train_df['Sentence'])\n",
    "    feature_space = vectorizer.transform(val_df['Sentence'])\n",
    "    \n",
    "    return feature_space.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_grams(train_df, val_df):\n",
    "\n",
    "    vectorizer = CountVectorizer(ngram_range = (2,2))\n",
    "\n",
    "    vectorizer.fit(train_df['Sentence'])\n",
    "    feature_space = vectorizer.transform(val_df['Sentence'])\n",
    "\n",
    "    return feature_space.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(train_df, val_df):\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    vectorizer.fit(train_df['Sentence'])\n",
    "    feature_space = vectorizer.transform(val_df['Sentence'])\n",
    "\n",
    "    return feature_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_n_grams(train_df, val_df):\n",
    "    vectorizer = CountVectorizer(ngram_range = (2,2))\n",
    "    transformer = TfidfTransformer()\n",
    "\n",
    "    vectorizer.fit(train_df['Sentence'])\n",
    "    transformer.fit(vectorizer)\n",
    "    feature_space = transformer.transform(val_df['Sentence'])\n",
    "\n",
    "    return feature_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "svc = SVC()\n",
    "knn = KNeighborsClassifier()\n",
    "nb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = [lr, svc, knn, nb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = [bag_of_words, n_grams, tf_idf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic_params = {\n",
    "#     'C': [0.1, 0.5],\n",
    "#     'penalty': ['l1', 'none'],\n",
    "#     'solver': ['lbfgs', 'saga']\n",
    "# }\n",
    "# svc_params = {\n",
    "#     'C': [0.5, 1],\n",
    "#     'kernel': ['sigmoid', 'rbf']\n",
    "# }\n",
    "# knc_params = {\n",
    "#     'n_neighbors': [5, 10],\n",
    "#     'weights' : ['uniform', 'distance']\n",
    "# }\n",
    "# nb_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params_list = [logistic_params, svc_params, knc_params, nb_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for feature in features:\n",
    "#     x = 0\n",
    "#     for model in models:\n",
    "#         gs = GridSearchCV(estimator=model,\n",
    "#                          param_grid=params_list[x],\n",
    "#                          scoring='accuracy',\n",
    "#                          verbose=1,\n",
    "#                          n_jobs=-1).fit(feature(train_data, train_data), train_data['Feeling'])\n",
    "#         x += 1\n",
    "#         y_train = gs.predict(feature(train_data, train_data))\n",
    "#         y_predict = gs.predict(feature(train_data, val_data))\n",
    "\n",
    "#         print(f\"Training Accuracy of {model} using {feature} %.3f\" \n",
    "#         %accuracy_score(train_data['Feeling'], y_train))\n",
    "\n",
    "#         print(f\"Training F1 of {model} using {feature} %.3f\" \n",
    "#         %f1_score(train_data['Feeling'], y_train, average = 'weighted'))\n",
    "\n",
    "#         print(f\"Val Accuracy of {model} using {feature} %.3f\" \n",
    "#         %accuracy_score(val_data['Feeling'], y_predict))\n",
    "\n",
    "#         print(f\"Val F1 of {model} using {feature} %.3f\" \n",
    "#         %f1_score(val_data['Feeling'], y_predict, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = 0\n",
    "# for model in models:\n",
    "#     gs = GridSearchCV(estimator=model,\n",
    "#                         param_grid=params_list[x],\n",
    "#                         scoring='accuracy',\n",
    "#                         verbose=1,\n",
    "#                         n_jobs=-1).fit(bag_of_words(train_data, train_data), train_data['Feeling'])\n",
    "#     x += 1\n",
    "#     y_train = gs.predict(bag_of_words(train_data, train_data))\n",
    "#     y_predict = gs.predict(bag_of_words(train_data, val_data))\n",
    "\n",
    "#     print(f\"Training Accuracy of {model} using bag_of_words %.3f\" \n",
    "#     %accuracy_score(train_data['Feeling'], y_train))\n",
    "\n",
    "#     print(f\"Training F1 of {model} using bag_of_words %.3f\" \n",
    "#     %f1_score(train_data['Feeling'], y_train, average = 'weighted'))\n",
    "\n",
    "#     print(f\"Val Accuracy of {model} using bag_of_words %.3f\" \n",
    "#     %accuracy_score(val_data['Feeling'], y_predict))\n",
    "\n",
    "#     print(f\"Val F1 of {model} using bag_of_words %.3f\" \n",
    "#     %f1_score(val_data['Feeling'], y_predict, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = 0\n",
    "# for model in models:\n",
    "#     gs = GridSearchCV(estimator=model,\n",
    "#                         param_grid=params_list[x],\n",
    "#                         scoring='accuracy',\n",
    "#                         verbose=1,\n",
    "#                         n_jobs=-1).fit(n_grams(train_data, train_data), train_data['Feeling'])\n",
    "#     x += 1\n",
    "#     y_train = gs.predict(n_grams(train_data, train_data))\n",
    "#     y_predict = gs.predict(n_grams(train_data, val_data))\n",
    "\n",
    "#     print(f\"Training Accuracy of {model} using n_grams %.3f\" \n",
    "#     %accuracy_score(train_data['Feeling'], y_train))\n",
    "\n",
    "#     print(f\"Training F1 of {model} using n_grams %.3f\" \n",
    "#     %f1_score(train_data['Feeling'], y_train, average = 'weighted'))\n",
    "\n",
    "#     print(f\"Val Accuracy of {model} using n_grams %.3f\" \n",
    "#     %accuracy_score(val_data['Feeling'], y_predict))\n",
    "\n",
    "#     print(f\"Val F1 of {model} using n_grams %.3f\" \n",
    "#     %f1_score(val_data['Feeling'], y_predict, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = 0\n",
    "# for model in models:\n",
    "#     gs = GridSearchCV(estimator=model,\n",
    "#                         param_grid=params_list[x],\n",
    "#                         scoring='accuracy',\n",
    "#                         verbose=1,\n",
    "#                         n_jobs=-1).fit(tf_idf(train_data, train_data), train_data['Feeling'])\n",
    "#     x += 1\n",
    "#     y_train = gs.predict(tf_idf(train_data, train_data))\n",
    "#     y_predict = gs.predict(tf_idf(train_data, val_data))\n",
    "\n",
    "#     print(f\"Training Accuracy of {model} using tf_idf %.3f\" \n",
    "#     %accuracy_score(train_data['Feeling'], y_train))\n",
    "\n",
    "#     print(f\"Training F1 of {model} using tf_idf %.3f\" \n",
    "#     %f1_score(train_data['Feeling'], y_train, average = 'weighted'))\n",
    "\n",
    "#     print(f\"Val Accuracy of {model} using tf_idf %.3f\" \n",
    "#     %accuracy_score(val_data['Feeling'], y_predict))\n",
    "\n",
    "#     print(f\"Val F1 of {model} using tf_idf %.3f\" \n",
    "#     %f1_score(val_data['Feeling'], y_predict, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelling Second Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [lr, svc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_params = {\n",
    "    'C': [0.1, 0.5],\n",
    "    'penalty': ['l1', 'none'],\n",
    "    'solver': ['lbfgs', 'saga']\n",
    "}\n",
    "svc_params = {\n",
    "    'C': [0.1, 0.5, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma' : [0.1, 1, 10, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list = [logistic_params, svc_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = [bag_of_words, tf_idf, n_grams, tf_idf_n_grams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Normal Bag of words\n",
    "\n",
    "# x = 0\n",
    "# for model in models:\n",
    "#     gs = GridSearchCV(estimator=model,\n",
    "#                         param_grid=params_list[x],\n",
    "#                         scoring='accuracy',\n",
    "#                         verbose=1,\n",
    "#                         n_jobs=-1).fit(bag_of_words(train_data, train_data), train_data['Feeling'])\n",
    "#     x += 1\n",
    "#     y_train = gs.predict(bag_of_words(train_data, train_data))\n",
    "#     y_predict = gs.predict(bag_of_words(train_data, val_data))\n",
    "\n",
    "#     print(f\"Training Accuracy of {model} using bag_of_words %.3f\" \n",
    "#     %accuracy_score(train_data['Feeling'], y_train))\n",
    "\n",
    "#     print(f\"Training F1 of {model} using bag_of_words %.3f\" \n",
    "#     %f1_score(train_data['Feeling'], y_train, average = 'weighted'))\n",
    "\n",
    "#     print(f\"Val Accuracy of {model} using bag_of_words %.3f\" \n",
    "#     %accuracy_score(val_data['Feeling'], y_predict))\n",
    "\n",
    "#     print(f\"Val F1 of {model} using bag_of_words %.3f\" \n",
    "#     %f1_score(val_data['Feeling'], y_predict, average = 'weighted'))\n",
    "\n",
    "#     print('Best parameters found:\\n', gs.best_params_)\n",
    "\n",
    "#     print('---------------------------------------------------------------------------------------------------------------------')\n",
    "#     # All results\n",
    "#     means = gs.cv_results_['mean_test_score']\n",
    "#     stds = gs.cv_results_['std_test_score']\n",
    "#     for mean, std, params in zip(means, stds, gs.cv_results_['params']):\n",
    "#         print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TF-IDF\n",
    "\n",
    "# x = 0\n",
    "# for model in models:\n",
    "#     gs = GridSearchCV(estimator=model,\n",
    "#                         param_grid=params_list[x],\n",
    "#                         scoring='accuracy',\n",
    "#                         verbose=1,\n",
    "#                         n_jobs=-1).fit(tf_idf(train_data, train_data), train_data['Feeling'])\n",
    "#     x += 1\n",
    "#     y_train = gs.predict(tf_idf(train_data, train_data))\n",
    "#     y_predict = gs.predict(tf_idf(train_data, val_data))\n",
    "\n",
    "#     print(f\"Training Accuracy of {model} using tf_idf %.3f\" \n",
    "#     %accuracy_score(train_data['Feeling'], y_train))\n",
    "\n",
    "#     print(f\"Training F1 of {model} using tf_idf %.3f\" \n",
    "#     %f1_score(train_data['Feeling'], y_train, average = 'weighted'))\n",
    "\n",
    "#     print(f\"Val Accuracy of {model} using tf_idf %.3f\" \n",
    "#     %accuracy_score(val_data['Feeling'], y_predict))\n",
    "\n",
    "#     print(f\"Val F1 of {model} using tf_idf %.3f\" \n",
    "#     %f1_score(val_data['Feeling'], y_predict, average = 'weighted'))\n",
    "\n",
    "#     print('Best parameters found:\\n', gs.best_params_)\n",
    "\n",
    "#     print('---------------------------------------------------------------------------------------------------------------------')\n",
    "#     # All results\n",
    "#     means = gs.cv_results_['mean_test_score']\n",
    "#     stds = gs.cv_results_['std_test_score']\n",
    "#     for mean, std, params in zip(means, stds, gs.cv_results_['params']):\n",
    "#         print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # N_Grams\n",
    "\n",
    "# x = 0\n",
    "# for model in models:\n",
    "#     gs = GridSearchCV(estimator=model,\n",
    "#                         param_grid=params_list[x],\n",
    "#                         scoring='accuracy',\n",
    "#                         verbose=1,\n",
    "#                         n_jobs=-1).fit(n_grams(train_data, train_data), train_data['Feeling'])\n",
    "#     x += 1\n",
    "#     y_train = gs.predict(n_grams(train_data, train_data))\n",
    "#     y_predict = gs.predict(n_grams(train_data, val_data))\n",
    "\n",
    "#     print(f\"Training Accuracy of {model} using n_grams %.3f\" \n",
    "#     %accuracy_score(train_data['Feeling'], y_train))\n",
    "\n",
    "#     print(f\"Training F1 of {model} using n_grams %.3f\" \n",
    "#     %f1_score(train_data['Feeling'], y_train, average = 'weighted'))\n",
    "\n",
    "#     print(f\"Val Accuracy of {model} using n_grams %.3f\" \n",
    "#     %accuracy_score(val_data['Feeling'], y_predict))\n",
    "\n",
    "#     print(f\"Val F1 of {model} using n_grams %.3f\" \n",
    "#     %f1_score(val_data['Feeling'], y_predict, average = 'weighted'))\n",
    "\n",
    "#     print('Best parameters found:\\n', gs.best_params_)\n",
    "\n",
    "#     print('---------------------------------------------------------------------------------------------------------------------')\n",
    "#     # All results\n",
    "#     means = gs.cv_results_['mean_test_score']\n",
    "#     stds = gs.cv_results_['std_test_score']\n",
    "#     for mean, std, params in zip(means, stds, gs.cv_results_['params']):\n",
    "#         print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TF_IDF_N_Grams\n",
    "\n",
    "# x = 0\n",
    "# for model in models:\n",
    "#     gs = GridSearchCV(estimator=model,\n",
    "#                         param_grid=params_list[x],\n",
    "#                         scoring='accuracy',\n",
    "#                         verbose=1,\n",
    "#                         n_jobs=-1).fit(tf_idf_n_grams(train_data, train_data), train_data['Feeling'])\n",
    "#     x += 1\n",
    "#     y_train = gs.predict(tf_idf_n_grams(train_data, train_data))\n",
    "#     y_predict = gs.predict(tf_idf_n_grams(train_data, val_data))\n",
    "\n",
    "#     print(f\"Training Accuracy of {model} using tf_idf_n_grams %.3f\" \n",
    "#     %accuracy_score(train_data['Feeling'], y_train))\n",
    "\n",
    "#     print(f\"Training F1 of {model} using tf_idf_n_grams %.3f\" \n",
    "#     %f1_score(train_data['Feeling'], y_train, average = 'weighted'))\n",
    "\n",
    "#     print(f\"Val Accuracy of {model} using tf_idf_n_grams %.3f\" \n",
    "#     %accuracy_score(val_data['Feeling'], y_predict))\n",
    "\n",
    "#     print(f\"Val F1 of {model} using tf_idf_n_grams %.3f\" \n",
    "#     %f1_score(val_data['Feeling'], y_predict, average = 'weighted'))\n",
    "\n",
    "#     print('Best parameters found:\\n', gs.best_params_)\n",
    "\n",
    "#     print('---------------------------------------------------------------------------------------------------------------------')\n",
    "#     # All results\n",
    "#     means = gs.cv_results_['mean_test_score']\n",
    "#     stds = gs.cv_results_['std_test_score']\n",
    "#     for mean, std, params in zip(means, stds, gs.cv_results_['params']):\n",
    "#         print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\conde\\anaconda3\\envs\\textmining\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "10 fits failed out of a total of 40.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\conde\\anaconda3\\envs\\textmining\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\conde\\anaconda3\\envs\\textmining\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\conde\\anaconda3\\envs\\textmining\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\conde\\anaconda3\\envs\\textmining\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.3075     0.33064286 0.36642857        nan 0.35835714\n",
      " 0.33064286 0.36678571]\n",
      "  warnings.warn(\n",
      "c:\\Users\\conde\\anaconda3\\envs\\textmining\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\conde\\anaconda3\\envs\\textmining\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy of Linear Regression using bag of words 0.696\n",
      "Training F1 of Linear Regression using bag of words 0.695\n",
      "Val Accuracy of Linear Regression using bag of words 0.356\n",
      "Val F1 of Linear Regression using bag of words 0.350\n",
      "Best parameters found:\n",
      " {'C': 0.5, 'penalty': 'none', 'solver': 'saga'}\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "nan (+/-nan) for {'C': 0.1, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.307 (+/-0.015) for {'C': 0.1, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.331 (+/-0.014) for {'C': 0.1, 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.366 (+/-0.026) for {'C': 0.1, 'penalty': 'none', 'solver': 'saga'}\n",
      "nan (+/-nan) for {'C': 0.5, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.358 (+/-0.017) for {'C': 0.5, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.331 (+/-0.014) for {'C': 0.5, 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.367 (+/-0.025) for {'C': 0.5, 'penalty': 'none', 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "# LR + BoW\n",
    "\n",
    "data = bag_of_words(train_data, train_data)\n",
    "eval_data = bag_of_words(train_data, val_data)\n",
    "\n",
    "method = \"bag of words\"\n",
    "model_used = 'Linear Regression'\n",
    "\n",
    "lr_bag_gs = GridSearchCV(estimator=lr,\n",
    "                    param_grid=params_list[0],\n",
    "                    scoring='accuracy',\n",
    "                    verbose=1,\n",
    "                    n_jobs=-1).fit(data, train_data['Feeling'])\n",
    "y_train = lr_bag_gs.predict(data)\n",
    "y_predict = lr_bag_gs.predict(eval_data)\n",
    "\n",
    "print(f\"Training Accuracy of {model_used} using {method} %.3f\" \n",
    "%accuracy_score(train_data['Feeling'], y_train))\n",
    "\n",
    "print(f\"Training F1 of {model_used} using {method} %.3f\" \n",
    "%f1_score(train_data['Feeling'], y_train, average = 'weighted'))\n",
    "\n",
    "print(f\"Val Accuracy of {model_used} using {method} %.3f\" \n",
    "%accuracy_score(val_data['Feeling'], y_predict))\n",
    "\n",
    "print(f\"Val F1 of {model_used} using {method} %.3f\" \n",
    "%f1_score(val_data['Feeling'], y_predict, average = 'weighted'))\n",
    "\n",
    "print('Best parameters found:\\n', lr_bag_gs.best_params_)\n",
    "\n",
    "print('---------------------------------------------------------------------------------------------------------------------')\n",
    "# All results\n",
    "means = lr_bag_gs.cv_results_['mean_test_score']\n",
    "stds = lr_bag_gs.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, lr_bag_gs.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\conde\\anaconda3\\envs\\textmining\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "10 fits failed out of a total of 40.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\conde\\anaconda3\\envs\\textmining\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\conde\\anaconda3\\envs\\textmining\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\conde\\anaconda3\\envs\\textmining\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\conde\\anaconda3\\envs\\textmining\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.26164286 0.32992857 0.32185714        nan 0.34721429\n",
      " 0.32992857 0.322     ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy of Linear Regression using tf-idf 0.393\n",
      "Training F1 of Linear Regression using tf-idf 0.373\n",
      "Val Accuracy of Linear Regression using tf-idf 0.363\n",
      "Val F1 of Linear Regression using tf-idf 0.342\n",
      "Best parameters found:\n",
      " {'C': 0.5, 'penalty': 'l1', 'solver': 'saga'}\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "nan (+/-nan) for {'C': 0.1, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.262 (+/-0.008) for {'C': 0.1, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.330 (+/-0.009) for {'C': 0.1, 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.322 (+/-0.009) for {'C': 0.1, 'penalty': 'none', 'solver': 'saga'}\n",
      "nan (+/-nan) for {'C': 0.5, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.347 (+/-0.011) for {'C': 0.5, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.330 (+/-0.009) for {'C': 0.5, 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.322 (+/-0.009) for {'C': 0.5, 'penalty': 'none', 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "#LR + TF-IDF\n",
    "\n",
    "data = tf_idf(train_data, train_data)\n",
    "eval_data = tf_idf(train_data, val_data)\n",
    "\n",
    "method = \"tf-idf\"\n",
    "model_used = 'Linear Regression'\n",
    "\n",
    "lr_tfidf_gs = GridSearchCV(estimator=lr,\n",
    "                    param_grid=params_list[0],\n",
    "                    scoring='accuracy',\n",
    "                    verbose=1,\n",
    "                    n_jobs=-1).fit(data, train_data['Feeling'])\n",
    "y_train = lr_tfidf_gs.predict(data)\n",
    "y_predict = lr_tfidf_gs.predict(eval_data)\n",
    "\n",
    "print(f\"Training Accuracy of {model_used} using {method} %.3f\" \n",
    "%accuracy_score(train_data['Feeling'], y_train))\n",
    "\n",
    "print(f\"Training F1 of {model_used} using {method} %.3f\" \n",
    "%f1_score(train_data['Feeling'], y_train, average = 'weighted'))\n",
    "\n",
    "print(f\"Val Accuracy of {model_used} using {method} %.3f\" \n",
    "%accuracy_score(val_data['Feeling'], y_predict))\n",
    "\n",
    "print(f\"Val F1 of {model_used} using {method} %.3f\" \n",
    "%f1_score(val_data['Feeling'], y_predict, average = 'weighted'))\n",
    "\n",
    "print('Best parameters found:\\n', lr_tfidf_gs.best_params_)\n",
    "\n",
    "print('---------------------------------------------------------------------------------------------------------------------')\n",
    "# All results\n",
    "means = lr_tfidf_gs.cv_results_['mean_test_score']\n",
    "stds = lr_tfidf_gs.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, lr_tfidf_gs.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 877. MiB for an array with shape (2800, 41049) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\conde\\anaconda3\\envs\\textmining\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 436, in _process_worker\n    r = call_item()\n  File \"c:\\Users\\conde\\anaconda3\\envs\\textmining\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 288, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"c:\\Users\\conde\\anaconda3\\envs\\textmining\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"c:\\Users\\conde\\anaconda3\\envs\\textmining\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"c:\\Users\\conde\\anaconda3\\envs\\textmining\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"c:\\Users\\conde\\anaconda3\\envs\\textmining\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n    return self.function(*args, **kwargs)\n  File \"c:\\Users\\conde\\anaconda3\\envs\\textmining\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 673, in _fit_and_score\n    X_test, y_test = _safe_split(estimator, X, y, test, train)\n  File \"c:\\Users\\conde\\anaconda3\\envs\\textmining\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 288, in _safe_split\n    X_subset = _safe_indexing(X, indices)\n  File \"c:\\Users\\conde\\anaconda3\\envs\\textmining\\lib\\site-packages\\sklearn\\utils\\__init__.py\", line 378, in _safe_indexing\n    return _array_indexing(X, indices, indices_dtype, axis=axis)\n  File \"c:\\Users\\conde\\anaconda3\\envs\\textmining\\lib\\site-packages\\sklearn\\utils\\__init__.py\", line 202, in _array_indexing\n    return array[key] if axis == 0 else array[:, key]\n  File \"c:\\Users\\conde\\anaconda3\\envs\\textmining\\lib\\site-packages\\numpy\\core\\memmap.py\", line 334, in __getitem__\n    res = super().__getitem__(index)\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 877. MiB for an array with shape (2800, 41049) and data type int64\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\conde\\OneDrive\\OneDrive Docs\\Documents\\Masters\\2nd semester\\Text Mining\\Project\\TextMining\\tm_notebook.ipynb Cell 39'\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/conde/OneDrive/OneDrive%20Docs/Documents/Masters/2nd%20semester/Text%20Mining/Project/TextMining/tm_notebook.ipynb#ch0000038?line=5'>6</a>\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mn-grams\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/conde/OneDrive/OneDrive%20Docs/Documents/Masters/2nd%20semester/Text%20Mining/Project/TextMining/tm_notebook.ipynb#ch0000038?line=6'>7</a>\u001b[0m model_used \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mLinear Regression\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/conde/OneDrive/OneDrive%20Docs/Documents/Masters/2nd%20semester/Text%20Mining/Project/TextMining/tm_notebook.ipynb#ch0000038?line=8'>9</a>\u001b[0m lr_ngrams_gs \u001b[39m=\u001b[39m GridSearchCV(estimator\u001b[39m=\u001b[39;49mlr,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/conde/OneDrive/OneDrive%20Docs/Documents/Masters/2nd%20semester/Text%20Mining/Project/TextMining/tm_notebook.ipynb#ch0000038?line=9'>10</a>\u001b[0m                     param_grid\u001b[39m=\u001b[39;49mparams_list[\u001b[39m0\u001b[39;49m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/conde/OneDrive/OneDrive%20Docs/Documents/Masters/2nd%20semester/Text%20Mining/Project/TextMining/tm_notebook.ipynb#ch0000038?line=10'>11</a>\u001b[0m                     scoring\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39maccuracy\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/conde/OneDrive/OneDrive%20Docs/Documents/Masters/2nd%20semester/Text%20Mining/Project/TextMining/tm_notebook.ipynb#ch0000038?line=11'>12</a>\u001b[0m                     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/conde/OneDrive/OneDrive%20Docs/Documents/Masters/2nd%20semester/Text%20Mining/Project/TextMining/tm_notebook.ipynb#ch0000038?line=12'>13</a>\u001b[0m                     n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49mfit(data, train_data[\u001b[39m'\u001b[39;49m\u001b[39mFeeling\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/conde/OneDrive/OneDrive%20Docs/Documents/Masters/2nd%20semester/Text%20Mining/Project/TextMining/tm_notebook.ipynb#ch0000038?line=13'>14</a>\u001b[0m y_train \u001b[39m=\u001b[39m lr_ngrams_gs\u001b[39m.\u001b[39mpredict(data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/conde/OneDrive/OneDrive%20Docs/Documents/Masters/2nd%20semester/Text%20Mining/Project/TextMining/tm_notebook.ipynb#ch0000038?line=14'>15</a>\u001b[0m y_predict \u001b[39m=\u001b[39m lr_ngrams_gs\u001b[39m.\u001b[39mpredict(eval_data)\n",
      "File \u001b[1;32mc:\\Users\\conde\\anaconda3\\envs\\textmining\\lib\\site-packages\\sklearn\\model_selection\\_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/model_selection/_search.py?line=884'>885</a>\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/model_selection/_search.py?line=885'>886</a>\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/model_selection/_search.py?line=886'>887</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/model_selection/_search.py?line=888'>889</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/model_selection/_search.py?line=890'>891</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/model_selection/_search.py?line=892'>893</a>\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/model_selection/_search.py?line=893'>894</a>\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/model_selection/_search.py?line=894'>895</a>\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\conde\\anaconda3\\envs\\textmining\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1392\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/model_selection/_search.py?line=1389'>1390</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/model_selection/_search.py?line=1390'>1391</a>\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/model_selection/_search.py?line=1391'>1392</a>\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\conde\\anaconda3\\envs\\textmining\\lib\\site-packages\\sklearn\\model_selection\\_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/model_selection/_search.py?line=829'>830</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/model_selection/_search.py?line=830'>831</a>\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/model_selection/_search.py?line=831'>832</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/model_selection/_search.py?line=832'>833</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/model_selection/_search.py?line=833'>834</a>\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/model_selection/_search.py?line=834'>835</a>\u001b[0m         )\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/model_selection/_search.py?line=835'>836</a>\u001b[0m     )\n\u001b[1;32m--> <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/model_selection/_search.py?line=837'>838</a>\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/model_selection/_search.py?line=838'>839</a>\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/model_selection/_search.py?line=839'>840</a>\u001b[0m         clone(base_estimator),\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/model_selection/_search.py?line=840'>841</a>\u001b[0m         X,\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/model_selection/_search.py?line=841'>842</a>\u001b[0m         y,\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/model_selection/_search.py?line=842'>843</a>\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/model_selection/_search.py?line=843'>844</a>\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/model_selection/_search.py?line=844'>845</a>\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/model_selection/_search.py?line=845'>846</a>\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/model_selection/_search.py?line=846'>847</a>\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/model_selection/_search.py?line=847'>848</a>\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/model_selection/_search.py?line=848'>849</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/model_selection/_search.py?line=849'>850</a>\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/model_selection/_search.py?line=850'>851</a>\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/model_selection/_search.py?line=851'>852</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/model_selection/_search.py?line=852'>853</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/model_selection/_search.py?line=854'>855</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/model_selection/_search.py?line=855'>856</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/model_selection/_search.py?line=856'>857</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/model_selection/_search.py?line=857'>858</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/model_selection/_search.py?line=858'>859</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/model_selection/_search.py?line=859'>860</a>\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\conde\\anaconda3\\envs\\textmining\\lib\\site-packages\\joblib\\parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/joblib/parallel.py?line=1052'>1053</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/joblib/parallel.py?line=1054'>1055</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/joblib/parallel.py?line=1055'>1056</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/joblib/parallel.py?line=1056'>1057</a>\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/joblib/parallel.py?line=1057'>1058</a>\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\conde\\anaconda3\\envs\\textmining\\lib\\site-packages\\joblib\\parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/joblib/parallel.py?line=932'>933</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/joblib/parallel.py?line=933'>934</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/joblib/parallel.py?line=934'>935</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/joblib/parallel.py?line=935'>936</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/joblib/parallel.py?line=936'>937</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\conde\\anaconda3\\envs\\textmining\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/joblib/_parallel_backends.py?line=538'>539</a>\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/joblib/_parallel_backends.py?line=539'>540</a>\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/joblib/_parallel_backends.py?line=540'>541</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/joblib/_parallel_backends.py?line=541'>542</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/joblib/_parallel_backends.py?line=542'>543</a>\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/joblib/_parallel_backends.py?line=543'>544</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\conde\\anaconda3\\envs\\textmining\\lib\\concurrent\\futures\\_base.py:446\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/concurrent/futures/_base.py?line=443'>444</a>\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/concurrent/futures/_base.py?line=444'>445</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/concurrent/futures/_base.py?line=445'>446</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/concurrent/futures/_base.py?line=446'>447</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/concurrent/futures/_base.py?line=447'>448</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32mc:\\Users\\conde\\anaconda3\\envs\\textmining\\lib\\concurrent\\futures\\_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/concurrent/futures/_base.py?line=388'>389</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/concurrent/futures/_base.py?line=389'>390</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/concurrent/futures/_base.py?line=390'>391</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/concurrent/futures/_base.py?line=391'>392</a>\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/concurrent/futures/_base.py?line=392'>393</a>\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/concurrent/futures/_base.py?line=393'>394</a>\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 877. MiB for an array with shape (2800, 41049) and data type int64"
     ]
    }
   ],
   "source": [
    "# LR + N-Grams\n",
    "\n",
    "data = n_grams(train_data, train_data)\n",
    "eval_data = n_grams(train_data, val_data)\n",
    "\n",
    "method = \"n-grams\"\n",
    "model_used = 'Linear Regression'\n",
    "\n",
    "lr_ngrams_gs = GridSearchCV(estimator=lr,\n",
    "                    param_grid=params_list[0],\n",
    "                    scoring='accuracy',\n",
    "                    verbose=1,\n",
    "                    n_jobs=-1).fit(data, train_data['Feeling'])\n",
    "y_train = lr_ngrams_gs.predict(data)\n",
    "y_predict = lr_ngrams_gs.predict(eval_data)\n",
    "\n",
    "print(f\"Training Accuracy of {model_used} using {method} %.3f\" \n",
    "%accuracy_score(train_data['Feeling'], y_train))\n",
    "\n",
    "print(f\"Training F1 of {model_used} using {method} %.3f\" \n",
    "%f1_score(train_data['Feeling'], y_train, average = 'weighted'))\n",
    "\n",
    "print(f\"Val Accuracy of {model_used} using {method} %.3f\" \n",
    "%accuracy_score(val_data['Feeling'], y_predict))\n",
    "\n",
    "print(f\"Val F1 of {model_used} using {method} %.3f\" \n",
    "%f1_score(val_data['Feeling'], y_predict, average = 'weighted'))\n",
    "\n",
    "print('Best parameters found:\\n', lr_ngrams_gs.best_params_)\n",
    "\n",
    "print('---------------------------------------------------------------------------------------------------------------------')\n",
    "# All results\n",
    "means = lr_ngrams_gs.cv_results_['mean_test_score']\n",
    "stds = lr_ngrams_gs.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, lr_ngrams_gs.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got scalar array instead:\narray=CountVectorizer(ngram_range=(2, 2)).\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\conde\\OneDrive\\OneDrive Docs\\Documents\\Masters\\2nd semester\\Text Mining\\Project\\TextMining\\tm_notebook.ipynb Cell 40'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/conde/OneDrive/OneDrive%20Docs/Documents/Masters/2nd%20semester/Text%20Mining/Project/TextMining/tm_notebook.ipynb#ch0000039?line=0'>1</a>\u001b[0m \u001b[39m#LR + TD-IDF of N-Grams\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/conde/OneDrive/OneDrive%20Docs/Documents/Masters/2nd%20semester/Text%20Mining/Project/TextMining/tm_notebook.ipynb#ch0000039?line=2'>3</a>\u001b[0m data \u001b[39m=\u001b[39m tf_idf_n_grams(train_data, train_data)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/conde/OneDrive/OneDrive%20Docs/Documents/Masters/2nd%20semester/Text%20Mining/Project/TextMining/tm_notebook.ipynb#ch0000039?line=3'>4</a>\u001b[0m eval_data \u001b[39m=\u001b[39m tf_idf_n_grams(train_data, val_data)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/conde/OneDrive/OneDrive%20Docs/Documents/Masters/2nd%20semester/Text%20Mining/Project/TextMining/tm_notebook.ipynb#ch0000039?line=5'>6</a>\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtf-idf of n-grams\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;32mc:\\Users\\conde\\OneDrive\\OneDrive Docs\\Documents\\Masters\\2nd semester\\Text Mining\\Project\\TextMining\\tm_notebook.ipynb Cell 17'\u001b[0m in \u001b[0;36mtf_idf_n_grams\u001b[1;34m(train_df, val_df)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/conde/OneDrive/OneDrive%20Docs/Documents/Masters/2nd%20semester/Text%20Mining/Project/TextMining/tm_notebook.ipynb#ch0000016?line=2'>3</a>\u001b[0m transformer \u001b[39m=\u001b[39m TfidfTransformer()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/conde/OneDrive/OneDrive%20Docs/Documents/Masters/2nd%20semester/Text%20Mining/Project/TextMining/tm_notebook.ipynb#ch0000016?line=4'>5</a>\u001b[0m vectorizer\u001b[39m.\u001b[39mfit(train_df[\u001b[39m'\u001b[39m\u001b[39mSentence\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/conde/OneDrive/OneDrive%20Docs/Documents/Masters/2nd%20semester/Text%20Mining/Project/TextMining/tm_notebook.ipynb#ch0000016?line=5'>6</a>\u001b[0m transformer\u001b[39m.\u001b[39;49mfit(vectorizer)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/conde/OneDrive/OneDrive%20Docs/Documents/Masters/2nd%20semester/Text%20Mining/Project/TextMining/tm_notebook.ipynb#ch0000016?line=6'>7</a>\u001b[0m feature_space \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mtransform(val_df[\u001b[39m'\u001b[39m\u001b[39mSentence\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/conde/OneDrive/OneDrive%20Docs/Documents/Masters/2nd%20semester/Text%20Mining/Project/TextMining/tm_notebook.ipynb#ch0000016?line=8'>9</a>\u001b[0m \u001b[39mreturn\u001b[39;00m feature_space\n",
      "File \u001b[1;32mc:\\Users\\conde\\anaconda3\\envs\\textmining\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1614\u001b[0m, in \u001b[0;36mTfidfTransformer.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/feature_extraction/text.py?line=1595'>1596</a>\u001b[0m \u001b[39m\"\"\"Learn the idf vector (global term weights).\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/feature_extraction/text.py?line=1596'>1597</a>\u001b[0m \n\u001b[0;32m   <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/feature_extraction/text.py?line=1597'>1598</a>\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/feature_extraction/text.py?line=1608'>1609</a>\u001b[0m \u001b[39m    Fitted transformer.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/feature_extraction/text.py?line=1609'>1610</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/feature_extraction/text.py?line=1610'>1611</a>\u001b[0m \u001b[39m# large sparse data is not supported for 32bit platforms because\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/feature_extraction/text.py?line=1611'>1612</a>\u001b[0m \u001b[39m# _document_frequency uses np.bincount which works on arrays of\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/feature_extraction/text.py?line=1612'>1613</a>\u001b[0m \u001b[39m# dtype NPY_INTP which is int32 for 32bit platforms. See #20923\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/feature_extraction/text.py?line=1613'>1614</a>\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m   <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/feature_extraction/text.py?line=1614'>1615</a>\u001b[0m     X, accept_sparse\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m), accept_large_sparse\u001b[39m=\u001b[39;49m\u001b[39mnot\u001b[39;49;00m _IS_32BIT\n\u001b[0;32m   <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/feature_extraction/text.py?line=1615'>1616</a>\u001b[0m )\n\u001b[0;32m   <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/feature_extraction/text.py?line=1616'>1617</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m sp\u001b[39m.\u001b[39missparse(X):\n\u001b[0;32m   <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/feature_extraction/text.py?line=1617'>1618</a>\u001b[0m     X \u001b[39m=\u001b[39m sp\u001b[39m.\u001b[39mcsr_matrix(X)\n",
      "File \u001b[1;32mc:\\Users\\conde\\anaconda3\\envs\\textmining\\lib\\site-packages\\sklearn\\base.py:566\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/base.py?line=563'>564</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/base.py?line=564'>565</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/base.py?line=565'>566</a>\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/base.py?line=566'>567</a>\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/base.py?line=567'>568</a>\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mc:\\Users\\conde\\anaconda3\\envs\\textmining\\lib\\site-packages\\sklearn\\utils\\validation.py:761\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/utils/validation.py?line=757'>758</a>\u001b[0m \u001b[39mif\u001b[39;00m ensure_2d:\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/utils/validation.py?line=758'>759</a>\u001b[0m     \u001b[39m# If input is scalar raise error\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/utils/validation.py?line=759'>760</a>\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/utils/validation.py?line=760'>761</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/utils/validation.py?line=761'>762</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got scalar array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/utils/validation.py?line=762'>763</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/utils/validation.py?line=763'>764</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/utils/validation.py?line=764'>765</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/utils/validation.py?line=765'>766</a>\u001b[0m         )\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/utils/validation.py?line=766'>767</a>\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/conde/anaconda3/envs/textmining/lib/site-packages/sklearn/utils/validation.py?line=767'>768</a>\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got scalar array instead:\narray=CountVectorizer(ngram_range=(2, 2)).\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "#LR + TD-IDF of N-Grams\n",
    "\n",
    "data = tf_idf_n_grams(train_data, train_data)\n",
    "eval_data = tf_idf_n_grams(train_data, val_data)\n",
    "\n",
    "method = \"tf-idf of n-grams\"\n",
    "model_used = 'Linear Regression'\n",
    "\n",
    "lr_ntfidf_gs = GridSearchCV(estimator=lr,\n",
    "                    param_grid=params_list[0],\n",
    "                    scoring='accuracy',\n",
    "                    verbose=1,\n",
    "                    n_jobs=-1).fit(data, train_data['Feeling'])\n",
    "y_train = lr_ntfidf_gs.predict(data)\n",
    "y_predict = lr_ntfidf_gs.predict(eval_data)\n",
    "\n",
    "print(f\"Training Accuracy of {model_used} using {method} %.3f\" \n",
    "%accuracy_score(train_data['Feeling'], y_train))\n",
    "\n",
    "print(f\"Training F1 of {model_used} using {method} %.3f\" \n",
    "%f1_score(train_data['Feeling'], y_train, average = 'weighted'))\n",
    "\n",
    "print(f\"Val Accuracy of {model_used} using {method} %.3f\" \n",
    "%accuracy_score(val_data['Feeling'], y_predict))\n",
    "\n",
    "print(f\"Val F1 of {model_used} using {method} %.3f\" \n",
    "%f1_score(val_data['Feeling'], y_predict, average = 'weighted'))\n",
    "\n",
    "print('Best parameters found:\\n', lr_ntfidf_gs.best_params_)\n",
    "\n",
    "print('---------------------------------------------------------------------------------------------------------------------')\n",
    "# All results\n",
    "means = lr_ntfidf_gs.cv_results_['mean_test_score']\n",
    "stds = lr_ntfidf_gs.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, lr_ntfidf_gs.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "# SVC + BoW\n",
    "\n",
    "data = bag_of_words(train_data, train_data)\n",
    "eval_data = bag_of_words(train_data, val_data)\n",
    "\n",
    "method = \"bag of words\"\n",
    "model_used = 'SVC'\n",
    "\n",
    "lr_bag_gs = GridSearchCV(estimator=svc,\n",
    "                    param_grid=params_list[1],\n",
    "                    scoring='accuracy',\n",
    "                    verbose=1,\n",
    "                    n_jobs=-1).fit(data, train_data['Feeling'])\n",
    "y_train = lr_bag_gs.predict(data)\n",
    "y_predict = lr_bag_gs.predict(eval_data)\n",
    "\n",
    "print(f\"Training Accuracy of {model_used} using {method} %.3f\" \n",
    "%accuracy_score(train_data['Feeling'], y_train))\n",
    "\n",
    "print(f\"Training F1 of {model_used} using {method} %.3f\" \n",
    "%f1_score(train_data['Feeling'], y_train, average = 'weighted'))\n",
    "\n",
    "print(f\"Val Accuracy of {model_used} using {method} %.3f\" \n",
    "%accuracy_score(val_data['Feeling'], y_predict))\n",
    "\n",
    "print(f\"Val F1 of {model_used} using {method} %.3f\" \n",
    "%f1_score(val_data['Feeling'], y_predict, average = 'weighted'))\n",
    "\n",
    "print('Best parameters found:\\n', lr_bag_gs.best_params_)\n",
    "\n",
    "print('---------------------------------------------------------------------------------------------------------------------')\n",
    "# All results\n",
    "means = lr_bag_gs.cv_results_['mean_test_score']\n",
    "stds = lr_bag_gs.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, lr_bag_gs.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC + BoW\n",
    "\n",
    "data = tf_idf(train_data, train_data)\n",
    "eval_data = tf_idf(train_data, val_data)\n",
    "\n",
    "method = \"bag of words\"\n",
    "model_used = 'SVC'\n",
    "\n",
    "svc_tfidf_gs = GridSearchCV(estimator=svc,\n",
    "                    param_grid=params_list[1],\n",
    "                    scoring='accuracy',\n",
    "                    verbose=1,\n",
    "                    n_jobs=-1).fit(data, train_data['Feeling'])\n",
    "y_train = svc_tfidf_gs.predict(data)\n",
    "y_predict = svc_tfidf_gs.predict(eval_data)\n",
    "\n",
    "print(f\"Training Accuracy of {model_used} using {method} %.3f\" \n",
    "%accuracy_score(train_data['Feeling'], y_train))\n",
    "\n",
    "print(f\"Training F1 of {model_used} using {method} %.3f\" \n",
    "%f1_score(train_data['Feeling'], y_train, average = 'weighted'))\n",
    "\n",
    "print(f\"Val Accuracy of {model_used} using {method} %.3f\" \n",
    "%accuracy_score(val_data['Feeling'], y_predict))\n",
    "\n",
    "print(f\"Val F1 of {model_used} using {method} %.3f\" \n",
    "%f1_score(val_data['Feeling'], y_predict, average = 'weighted'))\n",
    "\n",
    "print('Best parameters found:\\n', svc_tfidf_gs.best_params_)\n",
    "\n",
    "print('---------------------------------------------------------------------------------------------------------------------')\n",
    "# All results\n",
    "means = svc_tfidf_gs.cv_results_['mean_test_score']\n",
    "stds = svc_tfidf_gs.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, svc_tfidf_gs.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions = pd.read_csv(r\"C:\\Users\\conde\\OneDrive\\OneDrive Docs\\Documents\\Masters\\2nd semester\\Text Mining\\Project\\TextMining\\test_solution.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions = solutions[['sentence', 'emotion']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions.rename(columns = {'sentence':'Sentence', 'emotion':'Feeling'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\conde\\AppData\\Local\\Temp\\ipykernel_12752\\3798951257.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm(range(len(dataframe))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddf79c977a7d4b1d851b32c28fab45ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\conde\\anaconda3\\envs\\textmining\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "solutions = process(solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Feeling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>isaac cry cranky time</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sigh thought got good news</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cook</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dollar dollar every dollar taking west</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hundred produced every day sent sweatshop urba...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>bout flapping fish girl loved</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>happy blessing god blessing</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>night like moon</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>swapped trout</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>slimy cold seaweed dish ate</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence  Feeling\n",
       "0                                 isaac cry cranky time        4\n",
       "1                            sigh thought got good news        6\n",
       "2                                                  cook        7\n",
       "3                dollar dollar every dollar taking west        2\n",
       "4     hundred produced every day sent sweatshop urba...        1\n",
       "...                                                 ...      ...\n",
       "1995                      bout flapping fish girl loved        5\n",
       "1996                        happy blessing god blessing        5\n",
       "1997                                    night like moon        5\n",
       "1998                                      swapped trout        5\n",
       "1999                        slimy cold seaweed dish ate        3\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence    object\n",
       "Feeling      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solutions.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence    object\n",
       "Feeling     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\conde\\anaconda3\\envs\\textmining\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy of Linear Regression using tf-idf 0.447\n",
      "Training F1 of Linear Regression using tf-idf 0.436\n",
      "Val Accuracy of Linear Regression using tf-idf 0.335\n",
      "Val F1 of Linear Regression using tf-idf 0.319\n"
     ]
    }
   ],
   "source": [
    "data = bag_of_words(train_data, train_data)\n",
    "eval_data = bag_of_words(train_data, solutions)\n",
    "\n",
    "method = \"tf-idf\"\n",
    "model_used = 'Linear Regression'\n",
    "\n",
    "lr = LogisticRegression(C= 0.5, penalty = 'l1', solver = 'saga').fit(data, train_data['Feeling'])\n",
    "y_train = lr.predict(data)\n",
    "y_predict = lr.predict(eval_data)\n",
    "\n",
    "print(f\"Training Accuracy of {model_used} using {method} %.3f\" \n",
    "%accuracy_score(train_data['Feeling'], y_train))\n",
    "\n",
    "print(f\"Training F1 of {model_used} using {method} %.3f\" \n",
    "%f1_score(train_data['Feeling'], y_train, average = 'weighted'))\n",
    "\n",
    "print(f\"Val Accuracy of {model_used} using {method} %.3f\" \n",
    "%accuracy_score(solutions['Feeling'], y_predict.astype('int64')))\n",
    "\n",
    "print(f\"Val F1 of {model_used} using {method} %.3f\" \n",
    "%f1_score(solutions['Feeling'], y_predict.astype('int64'), average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\conde\\anaconda3\\envs\\textmining\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy of Linear Regression using tf-idf 0.388\n",
      "Training F1 of Linear Regression using tf-idf 0.366\n",
      "Val Accuracy of Linear Regression using tf-idf 0.213\n",
      "Val F1 of Linear Regression using tf-idf 0.094\n"
     ]
    }
   ],
   "source": [
    "data = n_grams(train_data, train_data)\n",
    "eval_data = n_grams(train_data, solutions)\n",
    "\n",
    "method = \"tf-idf\"\n",
    "model_used = 'Linear Regression'\n",
    "\n",
    "lr = LogisticRegression(C= 0.5, penalty = 'l1', solver = 'saga').fit(data, train_data['Feeling'])\n",
    "y_train = lr.predict(data)\n",
    "y_predict = lr.predict(eval_data)\n",
    "\n",
    "print(f\"Training Accuracy of {model_used} using {method} %.3f\" \n",
    "%accuracy_score(train_data['Feeling'], y_train))\n",
    "\n",
    "print(f\"Training F1 of {model_used} using {method} %.3f\" \n",
    "%f1_score(train_data['Feeling'], y_train, average = 'weighted'))\n",
    "\n",
    "print(f\"Val Accuracy of {model_used} using {method} %.3f\" \n",
    "%accuracy_score(solutions['Feeling'], y_predict.astype('int64')))\n",
    "\n",
    "print(f\"Val F1 of {model_used} using {method} %.3f\" \n",
    "%f1_score(solutions['Feeling'], y_predict.astype('int64'), average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f75349f0115edef59d2563a5bc200fd0b17f0436f327d8366fe82b1301064ec4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('textmining')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
